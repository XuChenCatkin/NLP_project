{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading passages from D:/NLP_Project/NLP_project/data/chunked_text_all_together_cleaned.json\n"
     ]
    }
   ],
   "source": [
    "from evaluation.eval_utils import *\n",
    "from evaluation.eval_utils import *\n",
    "import json\n",
    "from retrieval import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9251 corpus passages\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For text-based retrieval:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Import your evaluation framework.\n",
    "from evaluation.eval_utils import MetricCollection, RecallAtK, PrecisionAtK, MRR, nDCG\n",
    "\n",
    "#########################################\n",
    "# Retrieval Method Functions\n",
    "#########################################\n",
    "\n",
    "def tfidf_retrieval(query, config):\n",
    "    \"\"\"\n",
    "    TF-IDF retrieval.\n",
    "    config must include:\n",
    "      - \"vectorizer\": a fitted TfidfVectorizer,\n",
    "      - \"doc_matrix\": document-term matrix,\n",
    "      - \"passages\": list of passages,\n",
    "      - \"chunk_ids\": list of passage identifiers,\n",
    "      - \"top_k\": number of top results.\n",
    "    \"\"\"\n",
    "    vectorizer = config[\"vectorizer\"]\n",
    "    doc_matrix = config[\"doc_matrix\"]\n",
    "    passages = config[\"passages\"]\n",
    "    chunk_ids = config[\"chunk_ids\"]\n",
    "    top_k = config.get(\"top_k\", 5)\n",
    "    \n",
    "    query_vec = vectorizer.transform([query])\n",
    "    cosine_similarities = (doc_matrix @ query_vec.T).toarray().flatten()\n",
    "    sorted_indices = np.argsort(cosine_similarities)[::-1][:top_k]\n",
    "    \n",
    "    results = [{\"chunk_id\": chunk_ids[i], \"score\": float(cosine_similarities[i])} \n",
    "               for i in sorted_indices]\n",
    "    return results\n",
    "\n",
    "def bm25_retrieval(query, config):\n",
    "    \"\"\"\n",
    "    BM25 retrieval.\n",
    "    config must include:\n",
    "      - \"bm25\": a BM25Okapi object,\n",
    "      - \"passages\": list of passages,\n",
    "      - \"chunk_ids\": list of passage identifiers,\n",
    "      - \"top_k\": number of top results.\n",
    "    \"\"\"\n",
    "    bm25 = config[\"bm25\"]\n",
    "    passages = config[\"passages\"]\n",
    "    chunk_ids = config[\"chunk_ids\"]\n",
    "    top_k = config.get(\"top_k\", 5)\n",
    "    \n",
    "    tokenized_query = word_tokenize(query.lower())\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    sorted_indices = np.argsort(scores)[::-1][:top_k]\n",
    "    \n",
    "    results = [{\"chunk_id\": chunk_ids[i], \"score\": float(scores[i])} \n",
    "               for i in sorted_indices]\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def dense_retrieval_subqueries(queries, config):\n",
    "\n",
    "    if isinstance(queries, str):\n",
    "        queries = [queries]\n",
    "\n",
    "    results = []\n",
    "    top_k = config.get(\"top_k\", 5)\n",
    "    for query in queries:\n",
    "        query_emb = query_embed_search(query, config[\"all_subqueries\"], config[\"subquery_index\"])\n",
    "        query_emb = query_emb.reshape(1, -1)  # Reshape to (1, d)\n",
    "        distances, indices = config[\"faiss_index\"].search(query_emb, top_k)\n",
    "        results.extend([\n",
    "            {\n",
    "                \"sub_query\": query,\n",
    "                \"chunk_id\": config[\"chunk_ids\"][i],\n",
    "                \"passage\": config[\"passages\"][i],\n",
    "                \"score\": float(distances[0][j])\n",
    "            } for j, i in enumerate(indices[0])\n",
    "        ])\n",
    "    return results\n",
    "\n",
    "def query_embed_search(query, all_queries_list, index):\n",
    "    \"\"\"\n",
    "    Given a query, finds its embedding from the precomputed subqueries index.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        position = all_queries_list.index(query)\n",
    "        return index.reconstruct(position)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Query '{query}' not found in the list of all queries.\")\n",
    "    \n",
    "def hybrid(query, config):\n",
    "    \"\"\"\n",
    "    Hybrid retrieval: first uses a sparse retrieval method to get an intermediate set,\n",
    "    then re-ranks candidates using a dense retrieval function and returns the final top-k results.\n",
    "    \n",
    "    Parameters:\n",
    "      - query (str): The input query.\n",
    "      - config (dict): A configuration dictionary containing:\n",
    "            * \"sparse_func\": Function for sparse retrieval (e.g., tfidf_retrieval or bm25_retrieval).\n",
    "            * \"sparse_config\": Dictionary for the sparse retrieval configuration.\n",
    "            * \"dense_func\": Function for dense retrieval (e.g., dense_retrieval_subqueries).\n",
    "            * \"dense_config\": Dictionary for the dense retrieval configuration.\n",
    "            * \"intermediate_k\": Number of candidates to retrieve using the sparse method.\n",
    "            * \"final_k\": Number of final results to return after dense re-ranking.\n",
    "            * \"mode\": \"intersection\" (default) or \"union\".\n",
    "                - \"intersection\": Use only candidates present in the sparse results.\n",
    "                - \"union\": Combine candidates from both sparse and dense retrieval.\n",
    "                \n",
    "    Returns:\n",
    "      A list of dictionaries corresponding to the final top_k results.\n",
    "      Each dictionary includes at least \"chunk_id\" and \"score\" (dense score).\n",
    "    \"\"\"\n",
    "    if isinstance(query, list) and len(query) >= 2:\n",
    "        query_sparse = query[0]\n",
    "        query_dense = query[1]\n",
    "    else:\n",
    "        print(\"Query should be a list of two queries: [sparse_query, dense_query].\")\n",
    "    intermediate_k = config.get(\"intermediate_k\")\n",
    "    final_k = config.get(\"final_k\")\n",
    "    mode = config.get(\"mode\", \"intersection\")\n",
    "    \n",
    "    # Retrieve intermediate candidate set using the sparse retrieval function.\n",
    "    sparse_config = config[\"sparse_config\"].copy()\n",
    "    sparse_config[\"top_k\"] = intermediate_k\n",
    "    sparse_results = config[\"sparse_func\"](query_sparse, sparse_config)\n",
    "    \n",
    "    \n",
    "    # Retrieve dense results using the dense retrieval function.\n",
    "    dense_results = config[\"dense_func\"](query_dense, config[\"dense_config\"])\n",
    "    \n",
    "    if mode == \"intersection\":\n",
    "        # Use only candidates that appear in the sparse results.\n",
    "        candidate_ids = set(r[\"chunk_id\"] for r in sparse_results)\n",
    "        filtered_dense = [r for r in dense_results if r[\"chunk_id\"] in candidate_ids]\n",
    "        if not filtered_dense:\n",
    "            # If no overlap, fall back to all dense results.\n",
    "            filtered_dense = dense_results\n",
    "    elif mode == \"union\":\n",
    "        # Use the union of candidate IDs from sparse and dense retrieval.\n",
    "        candidate_ids = set(r[\"chunk_id\"] for r in sparse_results).union(\n",
    "                        set(r[\"chunk_id\"] for r in dense_results))\n",
    "        # Build a dictionary for dense results (using dense score), with default 0 if not present.\n",
    "        dense_dict = {r[\"chunk_id\"]: r for r in dense_results}\n",
    "        filtered_dense = []\n",
    "        for cid in candidate_ids:\n",
    "            if cid in dense_dict:\n",
    "                filtered_dense.append(dense_dict[cid])\n",
    "            else:\n",
    "                # If candidate from sparse isn't in dense, create a dummy entry with 0 score.\n",
    "                filtered_dense.append({\"chunk_id\": cid, \"score\": 0.0})\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Choose 'intersection' or 'union'.\")\n",
    "    \n",
    "    # Sort the filtered dense results by their dense score (highest first).\n",
    "    sorted_dense = sorted(filtered_dense, key=lambda x: x[\"score\"], reverse=True)\n",
    "    final_results = sorted_dense[:final_k]\n",
    "    return final_results\n",
    "def hybrid(query, config):\n",
    "    \"\"\"\n",
    "    Hybrid retrieval: first retrieve candidates with one method, then re-rank with the other.\n",
    "    \n",
    "    The order is determined by config[\"order\"]:\n",
    "      - \"sparse_dense\" (default): Use query[0] (or query if not a list) for sparse retrieval,\n",
    "                                   then query[1] (or query) for dense retrieval.\n",
    "      - \"dense_sparse\": Use query[0] for dense retrieval,\n",
    "                        then query[1] for sparse retrieval.\n",
    "    \n",
    "    The candidate sets are combined (using the \"mode\": \"intersection\" or \"union\")\n",
    "    and then sorted by the score of the re-ranking model.\n",
    "    \n",
    "    Parameters:\n",
    "      - query (str or list): If a list of at least two elements, the two parts will be used\n",
    "                             in the order specified by config[\"order\"]. Otherwise, the same query is used.\n",
    "      - config (dict): Must contain:\n",
    "          * \"order\": either \"sparse_dense\" (default) or \"dense_sparse\"\n",
    "          * \"sparse_func\": sparse retrieval function (e.g., tfidf_retrieval or bm25_retrieval)\n",
    "          * \"sparse_config\": configuration for the sparse method.\n",
    "          * \"dense_func\": dense retrieval function (e.g., dense_retrieval_subqueries)\n",
    "          * \"dense_config\": configuration for the dense method.\n",
    "          * \"intermediate_k\": candidate set size (default: 30)\n",
    "          * \"final_k\": final result count (default: 5)\n",
    "          * \"mode\": \"intersection\" (default) or \"union\"\n",
    "    \n",
    "    Returns:\n",
    "      A list of final results (dictionaries) from the re-ranking step.\n",
    "    \"\"\"\n",
    "    order = config.get(\"order\", \"sparse_dense\")\n",
    "    intermediate_k = config.get(\"intermediate_k\", 30)\n",
    "    final_k = config.get(\"final_k\", 5)\n",
    "    mode = config.get(\"mode\", \"intersection\")\n",
    "    \n",
    "    # Decide which query part to use for each retrieval step.\n",
    "    if isinstance(query, list) and len(query) >= 2:\n",
    "        query_sparse = query[0]\n",
    "        query_dense = query[1]\n",
    "    else:\n",
    "        print(\"Query should be a list of two queries: [sparse_query, dense_query].\")\n",
    "\n",
    "\n",
    "    if order == \"sparse_dense\":\n",
    "        # Sparse retrieval first.\n",
    "        sparse_config = config[\"sparse_config\"].copy()\n",
    "        sparse_config[\"top_k\"] = intermediate_k\n",
    "        sparse_results = config[\"sparse_func\"](query_sparse, sparse_config)\n",
    "        \n",
    "        # Dense retrieval.\n",
    "        dense_results = config[\"dense_func\"](query_dense, config[\"dense_config\"])\n",
    "        \n",
    "        # Combine: here we choose to filter dense results by the candidate set from sparse.\n",
    "        candidate_ids = set(r[\"chunk_id\"] for r in sparse_results)\n",
    "        filtered_dense = [r for r in dense_results if r[\"chunk_id\"] in candidate_ids]\n",
    "        if not filtered_dense:\n",
    "            filtered_dense = dense_results\n",
    "        # Sort by dense score.\n",
    "        sorted_results = sorted(filtered_dense, key=lambda x: x[\"score\"], reverse=True)\n",
    "    \n",
    "    elif order == \"dense_sparse\":\n",
    "        # Dense retrieval first.\n",
    "        dense_results = config[\"dense_func\"](query_dense, config[\"dense_config\"])\n",
    "        # Sparse retrieval.\n",
    "        sparse_config = config[\"sparse_config\"].copy()\n",
    "        sparse_config[\"top_k\"] = intermediate_k\n",
    "        sparse_results = config[\"sparse_func\"](query_sparse, sparse_config)\n",
    "        # Combine: filter sparse results by dense candidate set.\n",
    "        candidate_ids = set(r[\"chunk_id\"] for r in dense_results)\n",
    "        filtered_sparse = [r for r in sparse_results if r[\"chunk_id\"] in candidate_ids]\n",
    "        if not filtered_sparse:\n",
    "            filtered_sparse = sparse_results\n",
    "        # Sort by sparse score.\n",
    "        sorted_results = sorted(filtered_sparse, key=lambda x: x[\"score\"], reverse=True)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid order specified.\")\n",
    "    \n",
    "    return sorted_results[:final_k]\n",
    "\n",
    "#########################################\n",
    "# Dataset Configuration\n",
    "#########################################\n",
    "\n",
    "# Global corpus (for all retrieval methods that use it).\n",
    "def load_corpus(corpus_file):\n",
    "    with open(corpus_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    passages = [entry[\"passage\"] for entry in data if \"passage\" in entry]\n",
    "    chunk_ids = [entry[\"chunk_id\"] for entry in data if \"chunk_id\" in entry]\n",
    "    print(f\"Loaded {len(passages)} corpus passages\")\n",
    "    return passages, chunk_ids\n",
    "\n",
    "# Paths for the corpus and QA sets.\n",
    "CORPUS_FILE = \"./data/chunked_text_all_together_cleaned.json\"\n",
    "QA_PATH = \"./data/QA_set\"\n",
    "QA_EMBEDDED_PATH = \"./embedding/dpr\"\n",
    "\n",
    "# Load the corpus and build common indexes.\n",
    "passages, chunk_ids = load_corpus(CORPUS_FILE)\n",
    "\n",
    "# Build TF-IDF index for the corpus.\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "doc_matrix = tfidf_vectorizer.fit_transform(passages)\n",
    "\n",
    "# Build BM25 index for the corpus.\n",
    "tokenized_passages = [word_tokenize(p.lower()) for p in passages]\n",
    "bm25 = BM25Okapi(tokenized_passages)\n",
    "\n",
    "# Load global dense corpus index (FAISS).\n",
    "corpus_dense_index = faiss.read_index(\"embedding/dpr/hp_all_dpr.index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'easy_single': loaded 253 ground truth examples.\n",
      "Evaluated tfidf on easy_single: {'recall@5': 0.08389261744966443, 'recall@10': 0.12416107382550336, 'precision@5': 0.004940711462450593, 'precision@10': 0.007312252964426878, 'mrr': 0.0647274655644802, 'ndcg@5': 0.05913122106512458, 'ndcg@10': 0.07361285003547607}\n",
      "Evaluated bm25 on easy_single: {'recall@5': 0.08389261744966443, 'recall@10': 0.15436241610738255, 'precision@5': 0.004940711462450593, 'precision@10': 0.00909090909090909, 'mrr': 0.0636334769291915, 'ndcg@5': 0.05909196015880151, 'ndcg@10': 0.08244786017469655}\n",
      "Evaluated dense on easy_single: {'recall@5': 0.04697986577181208, 'recall@10': 0.06711409395973154, 'precision@5': 0.002766798418972332, 'precision@10': 0.003952569169960474, 'mrr': 0.034200157485439975, 'ndcg@5': 0.03222963502354667, 'ndcg@10': 0.03851870914294655}\n",
      "Evaluated tfidf_dense on easy_single: {'recall@5': 0.04697986577181208, 'recall@10': 0.06040268456375839, 'precision@5': 0.007927519818799546, 'precision@10': 0.010192525481313703, 'mrr': 0.03290684940882569, 'ndcg@5': 0.034232750786894674, 'ndcg@10': 0.038905654676266735}\n",
      "Evaluated bm25_dense on easy_single: {'recall@5': 0.053691275167785234, 'recall@10': 0.06375838926174497, 'precision@5': 0.010178117048346057, 'precision@10': 0.012086513994910942, 'mrr': 0.03749151595001398, 'ndcg@5': 0.03959682422082759, 'ndcg@10': 0.04328045959329968}\n",
      "Evaluated dense_tfidf on easy_single: {'recall@5': 0.050335570469798654, 'recall@10': 0.06040268456375839, 'precision@5': 0.008493771234428085, 'precision@10': 0.010192525481313703, 'mrr': 0.039829735481909385, 'ndcg@5': 0.040933616630268205, 'ndcg@10': 0.04483534366852702}\n",
      "Evaluated dense_bm25 on easy_single: {'recall@5': 0.053691275167785234, 'recall@10': 0.06711409395973154, 'precision@5': 0.010178117048346057, 'precision@10': 0.01272264631043257, 'mrr': 0.04365236213062299, 'ndcg@5': 0.04400652911865509, 'ndcg@10': 0.04858902251879914}\n",
      "Dataset 'medium_single': loaded 91 ground truth examples.\n",
      "Evaluated tfidf on medium_single: {'recall@5': 0.136, 'recall@10': 0.184, 'precision@5': 0.00934065934065934, 'precision@10': 0.012637362637362638, 'mrr': 0.1221554696829422, 'ndcg@5': 0.1106424051223992, 'ndcg@10': 0.12665075284931043}\n",
      "Evaluated bm25 on medium_single: {'recall@5': 0.12, 'recall@10': 0.16, 'precision@5': 0.008241758241758242, 'precision@10': 0.01098901098901099, 'mrr': 0.11703980743888205, 'ndcg@5': 0.11453206515215979, 'ndcg@10': 0.1288959184344231}\n",
      "Evaluated dense on medium_single: {'recall@5': 0.08, 'recall@10': 0.096, 'precision@5': 0.0018315018315018315, 'precision@10': 0.002197802197802198, 'mrr': 0.07126817332387624, 'ndcg@5': 0.06565327326621338, 'ndcg@10': 0.07242794219423218}\n",
      "Evaluated tfidf_dense on medium_single: {'recall@5': 0.08, 'recall@10': 0.096, 'precision@5': 0.006570302233902759, 'precision@10': 0.00788436268068331, 'mrr': 0.07989574528036067, 'ndcg@5': 0.08674843448069326, 'ndcg@10': 0.10246924304412725}\n",
      "Evaluated bm25_dense on medium_single: {'recall@5': 0.072, 'recall@10': 0.096, 'precision@5': 0.005984042553191489, 'precision@10': 0.007978723404255319, 'mrr': 0.07585839069355554, 'ndcg@5': 0.07959545723006542, 'ndcg@10': 0.09986775470330898}\n",
      "Evaluated dense_tfidf on medium_single: {'recall@5': 0.104, 'recall@10': 0.104, 'precision@5': 0.00980392156862745, 'precision@10': 0.00980392156862745, 'mrr': 0.08992673992673993, 'ndcg@5': 0.08519435273356885, 'ndcg@10': 0.08519435273356885}\n",
      "Evaluated dense_bm25 on medium_single: {'recall@5': 0.064, 'recall@10': 0.104, 'precision@5': 0.006600660066006601, 'precision@10': 0.010726072607260726, 'mrr': 0.08020451770451771, 'ndcg@5': 0.06513199631359695, 'ndcg@10': 0.08213547635188177}\n",
      "Dataset 'medium_multi': loaded 35 ground truth examples.\n",
      "Evaluated tfidf on medium_multi: {'recall@5': 0.006802721088435374, 'recall@10': 0.006802721088435374, 'precision@5': 0.0014285714285714286, 'precision@10': 0.0014285714285714286, 'mrr': 0.03211600429645542, 'ndcg@5': 0.017518491221870238, 'ndcg@10': 0.017518491221870238}\n",
      "Evaluated bm25 on medium_multi: {'recall@5': 0.027210884353741496, 'recall@10': 0.04081632653061224, 'precision@5': 0.005714285714285714, 'precision@10': 0.008571428571428572, 'mrr': 0.06294610151753008, 'ndcg@5': 0.03288943101954012, 'ndcg@10': 0.03629333292455425}\n",
      "Evaluated dense on medium_multi: {'recall@5': 0.006802721088435374, 'recall@10': 0.02040816326530612, 'precision@5': 0.0004761904761904762, 'precision@10': 0.0014285714285714286, 'mrr': 0.024303930236993117, 'ndcg@5': 0.0061138932781293585, 'ndcg@10': 0.01099536190337637}\n",
      "Evaluated tfidf_dense on medium_multi: {'recall@5': 0.013605442176870748, 'recall@10': 0.027210884353741496, 'precision@5': 0.00404040404040404, 'precision@10': 0.00808080808080808, 'mrr': 0.03493300350443208, 'ndcg@5': 0.011690751135159383, 'ndcg@10': 0.021678546745347697}\n",
      "Evaluated bm25_dense on medium_multi: {'recall@5': 0.006802721088435374, 'recall@10': 0.02040816326530612, 'precision@5': 0.0022522522522522522, 'precision@10': 0.006756756756756757, 'mrr': 0.01746031746031746, 'ndcg@5': 0.004845145789623088, 'ndcg@10': 0.010933376807474382}\n",
      "Evaluated dense_tfidf on medium_multi: {'recall@5': 0.02040816326530612, 'recall@10': 0.04081632653061224, 'precision@5': 0.007425742574257425, 'precision@10': 0.01485148514851485, 'mrr': 0.053015873015873016, 'ndcg@5': 0.01974757800403576, 'ndcg@10': 0.029312817750386008}\n",
      "Evaluated dense_bm25 on medium_multi: {'recall@5': 0.013605442176870748, 'recall@10': 0.02040816326530612, 'precision@5': 0.0056657223796034, 'precision@10': 0.0084985835694051, 'mrr': 0.02, 'ndcg@5': 0.008593862289975709, 'ndcg@10': 0.01189466446716484}\n",
      "Dataset 'hard_single': loaded 11 ground truth examples.\n",
      "Evaluated tfidf on hard_single: {'recall@5': 0.05555555555555555, 'recall@10': 0.1111111111111111, 'precision@5': 0.004545454545454545, 'precision@10': 0.00909090909090909, 'mrr': 0.045454545454545456, 'ndcg@5': 0.02787032694388447, 'ndcg@10': 0.06025279849915921}\n",
      "Evaluated bm25 on hard_single: {'recall@5': 0.1111111111111111, 'recall@10': 0.1111111111111111, 'precision@5': 0.00909090909090909, 'precision@10': 0.00909090909090909, 'mrr': 0.045454545454545456, 'ndcg@5': 0.06315860733145308, 'ndcg@10': 0.06315860733145308}\n",
      "Evaluated dense on hard_single: {'recall@5': 0.1111111111111111, 'recall@10': 0.1111111111111111, 'precision@5': 0.0030303030303030303, 'precision@10': 0.0030303030303030303, 'mrr': 0.10909090909090909, 'ndcg@5': 0.10741289023066841, 'ndcg@10': 0.10741289023066841}\n",
      "Evaluated tfidf_dense on hard_single: {'recall@5': 0.05555555555555555, 'recall@10': 0.05555555555555555, 'precision@5': 0.00625, 'precision@10': 0.00625, 'mrr': 0.09090909090909091, 'ndcg@5': 0.19372088668831433, 'ndcg@10': 0.19372088668831433}\n",
      "Evaluated bm25_dense on hard_single: {'recall@5': 0.05555555555555555, 'recall@10': 0.05555555555555555, 'precision@5': 0.007194244604316547, 'precision@10': 0.007194244604316547, 'mrr': 0.09090909090909091, 'ndcg@5': 0.19372088668831433, 'ndcg@10': 0.19372088668831433}\n",
      "Evaluated dense_tfidf on hard_single: {'recall@5': 0.05555555555555555, 'recall@10': 0.05555555555555555, 'precision@5': 0.007518796992481203, 'precision@10': 0.007518796992481203, 'mrr': 0.045454545454545456, 'ndcg@5': 0.05735725032467796, 'ndcg@10': 0.05735725032467796}\n",
      "Evaluated dense_bm25 on hard_single: {'recall@5': 0.05555555555555555, 'recall@10': 0.05555555555555555, 'precision@5': 0.008695652173913044, 'precision@10': 0.008695652173913044, 'mrr': 0.09090909090909091, 'ndcg@5': 0.09090909090909091, 'ndcg@10': 0.09090909090909091}\n",
      "Dataset 'hard_multi': loaded 12 ground truth examples.\n",
      "Evaluated tfidf on hard_multi: {'recall@5': 0.08333333333333333, 'recall@10': 0.08333333333333333, 'precision@5': 0.008333333333333333, 'precision@10': 0.008333333333333333, 'mrr': 0.05555555555555555, 'ndcg@5': 0.05109559939712153, 'ndcg@10': 0.05109559939712153}\n",
      "Evaluated bm25 on hard_multi: {'recall@5': 0.041666666666666664, 'recall@10': 0.041666666666666664, 'precision@5': 0.004166666666666667, 'precision@10': 0.004166666666666667, 'mrr': 0.027777777777777776, 'ndcg@5': 0.025547799698560764, 'ndcg@10': 0.025547799698560764}\n",
      "Evaluated dense on hard_multi: {'recall@5': 0.0, 'recall@10': 0.0, 'precision@5': 0.0, 'precision@10': 0.0, 'mrr': 0.0, 'ndcg@5': 0.0, 'ndcg@10': 0.0}\n",
      "Evaluated tfidf_dense on hard_multi: {'recall@5': 0.0, 'recall@10': 0.0, 'precision@5': 0.0, 'precision@10': 0.0, 'mrr': 0.0, 'ndcg@5': 0.0, 'ndcg@10': 0.0}\n",
      "Evaluated bm25_dense on hard_multi: {'recall@5': 0.0, 'recall@10': 0.0, 'precision@5': 0.0, 'precision@10': 0.0, 'mrr': 0.0, 'ndcg@5': 0.0, 'ndcg@10': 0.0}\n",
      "Evaluated dense_tfidf on hard_multi: {'recall@5': 0.0, 'recall@10': 0.0, 'precision@5': 0.0, 'precision@10': 0.0, 'mrr': 0.0, 'ndcg@5': 0.0, 'ndcg@10': 0.0}\n",
      "Evaluated dense_bm25 on hard_multi: {'recall@5': 0.0, 'recall@10': 0.0, 'precision@5': 0.0, 'precision@10': 0.0, 'mrr': 0.0, 'ndcg@5': 0.0, 'ndcg@10': 0.0}\n",
      "Dataset 'test': loaded 83 ground truth examples.\n",
      "Evaluated tfidf on test: {'recall@5': 0.07092198581560284, 'recall@10': 0.09219858156028368, 'precision@5': 0.006024096385542169, 'precision@10': 0.00783132530120482, 'mrr': 0.07704149933065596, 'ndcg@5': 0.07513686525367662, 'ndcg@10': 0.0863652959673566}\n",
      "Evaluated bm25 on test: {'recall@5': 0.07801418439716312, 'recall@10': 0.12056737588652482, 'precision@5': 0.006626506024096385, 'precision@10': 0.010240963855421687, 'mrr': 0.09369425754967924, 'ndcg@5': 0.09114691312944778, 'ndcg@10': 0.11203317354451774}\n",
      "Evaluated dense on test: {'recall@5': 0.0425531914893617, 'recall@10': 0.05673758865248227, 'precision@5': 0.0020408163265306124, 'precision@10': 0.0027210884353741495, 'mrr': 0.05249844847647824, 'ndcg@5': 0.045027110294652076, 'ndcg@10': 0.05245475936031123}\n",
      "Evaluated tfidf_dense on test: {'recall@5': 0.0425531914893617, 'recall@10': 0.06382978723404255, 'precision@5': 0.006952491309385863, 'precision@10': 0.010428736964078795, 'mrr': 0.06817790643091848, 'ndcg@5': 0.06636319360131937, 'ndcg@10': 0.08152091295853581}\n",
      "Evaluated bm25_dense on test: {'recall@5': 0.03546099290780142, 'recall@10': 0.05673758865248227, 'precision@5': 0.005917159763313609, 'precision@10': 0.009467455621301775, 'mrr': 0.05655044420104661, 'ndcg@5': 0.05579433438037901, 'ndcg@10': 0.06997607482792381}\n",
      "Evaluated dense_tfidf on test: {'recall@5': 0.04964539007092199, 'recall@10': 0.06382978723404255, 'precision@5': 0.008917197452229299, 'precision@10': 0.011464968152866241, 'mrr': 0.061746987951807226, 'ndcg@5': 0.0573718012908785, 'ndcg@10': 0.06280694406459147}\n",
      "Evaluated dense_bm25 on test: {'recall@5': 0.03546099290780142, 'recall@10': 0.07092198581560284, 'precision@5': 0.006587615283267457, 'precision@10': 0.013175230566534914, 'mrr': 0.056855995410212266, 'ndcg@5': 0.04840701880489156, 'ndcg@10': 0.0671578661261778}\n",
      "Final Results:\n",
      "[{'data_set': 'easy_single', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.08389261744966443, 'recall@10': 0.12416107382550336, 'precision@5': 0.004940711462450593, 'precision@10': 0.007312252964426878, 'mrr': 0.0647274655644802, 'ndcg@5': 0.05913122106512458, 'ndcg@10': 0.07361285003547607}}, {'data_set': 'easy_single', 'retrieval': 'bm25', 'performance': {'recall@5': 0.08389261744966443, 'recall@10': 0.15436241610738255, 'precision@5': 0.004940711462450593, 'precision@10': 0.00909090909090909, 'mrr': 0.0636334769291915, 'ndcg@5': 0.05909196015880151, 'ndcg@10': 0.08244786017469655}}, {'data_set': 'easy_single', 'retrieval': 'dense', 'performance': {'recall@5': 0.04697986577181208, 'recall@10': 0.06711409395973154, 'precision@5': 0.002766798418972332, 'precision@10': 0.003952569169960474, 'mrr': 0.034200157485439975, 'ndcg@5': 0.03222963502354667, 'ndcg@10': 0.03851870914294655}}, {'data_set': 'easy_single', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.04697986577181208, 'recall@10': 0.06040268456375839, 'precision@5': 0.007927519818799546, 'precision@10': 0.010192525481313703, 'mrr': 0.03290684940882569, 'ndcg@5': 0.034232750786894674, 'ndcg@10': 0.038905654676266735}}, {'data_set': 'easy_single', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.053691275167785234, 'recall@10': 0.06375838926174497, 'precision@5': 0.010178117048346057, 'precision@10': 0.012086513994910942, 'mrr': 0.03749151595001398, 'ndcg@5': 0.03959682422082759, 'ndcg@10': 0.04328045959329968}}, {'data_set': 'easy_single', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.050335570469798654, 'recall@10': 0.06040268456375839, 'precision@5': 0.008493771234428085, 'precision@10': 0.010192525481313703, 'mrr': 0.039829735481909385, 'ndcg@5': 0.040933616630268205, 'ndcg@10': 0.04483534366852702}}, {'data_set': 'easy_single', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.053691275167785234, 'recall@10': 0.06711409395973154, 'precision@5': 0.010178117048346057, 'precision@10': 0.01272264631043257, 'mrr': 0.04365236213062299, 'ndcg@5': 0.04400652911865509, 'ndcg@10': 0.04858902251879914}}, {'data_set': 'medium_single', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.136, 'recall@10': 0.184, 'precision@5': 0.00934065934065934, 'precision@10': 0.012637362637362638, 'mrr': 0.1221554696829422, 'ndcg@5': 0.1106424051223992, 'ndcg@10': 0.12665075284931043}}, {'data_set': 'medium_single', 'retrieval': 'bm25', 'performance': {'recall@5': 0.12, 'recall@10': 0.16, 'precision@5': 0.008241758241758242, 'precision@10': 0.01098901098901099, 'mrr': 0.11703980743888205, 'ndcg@5': 0.11453206515215979, 'ndcg@10': 0.1288959184344231}}, {'data_set': 'medium_single', 'retrieval': 'dense', 'performance': {'recall@5': 0.08, 'recall@10': 0.096, 'precision@5': 0.0018315018315018315, 'precision@10': 0.002197802197802198, 'mrr': 0.07126817332387624, 'ndcg@5': 0.06565327326621338, 'ndcg@10': 0.07242794219423218}}, {'data_set': 'medium_single', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.08, 'recall@10': 0.096, 'precision@5': 0.006570302233902759, 'precision@10': 0.00788436268068331, 'mrr': 0.07989574528036067, 'ndcg@5': 0.08674843448069326, 'ndcg@10': 0.10246924304412725}}, {'data_set': 'medium_single', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.072, 'recall@10': 0.096, 'precision@5': 0.005984042553191489, 'precision@10': 0.007978723404255319, 'mrr': 0.07585839069355554, 'ndcg@5': 0.07959545723006542, 'ndcg@10': 0.09986775470330898}}, {'data_set': 'medium_single', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.104, 'recall@10': 0.104, 'precision@5': 0.00980392156862745, 'precision@10': 0.00980392156862745, 'mrr': 0.08992673992673993, 'ndcg@5': 0.08519435273356885, 'ndcg@10': 0.08519435273356885}}, {'data_set': 'medium_single', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.064, 'recall@10': 0.104, 'precision@5': 0.006600660066006601, 'precision@10': 0.010726072607260726, 'mrr': 0.08020451770451771, 'ndcg@5': 0.06513199631359695, 'ndcg@10': 0.08213547635188177}}, {'data_set': 'medium_multi', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.006802721088435374, 'recall@10': 0.006802721088435374, 'precision@5': 0.0014285714285714286, 'precision@10': 0.0014285714285714286, 'mrr': 0.03211600429645542, 'ndcg@5': 0.017518491221870238, 'ndcg@10': 0.017518491221870238}}, {'data_set': 'medium_multi', 'retrieval': 'bm25', 'performance': {'recall@5': 0.027210884353741496, 'recall@10': 0.04081632653061224, 'precision@5': 0.005714285714285714, 'precision@10': 0.008571428571428572, 'mrr': 0.06294610151753008, 'ndcg@5': 0.03288943101954012, 'ndcg@10': 0.03629333292455425}}, {'data_set': 'medium_multi', 'retrieval': 'dense', 'performance': {'recall@5': 0.006802721088435374, 'recall@10': 0.02040816326530612, 'precision@5': 0.0004761904761904762, 'precision@10': 0.0014285714285714286, 'mrr': 0.024303930236993117, 'ndcg@5': 0.0061138932781293585, 'ndcg@10': 0.01099536190337637}}, {'data_set': 'medium_multi', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.013605442176870748, 'recall@10': 0.027210884353741496, 'precision@5': 0.00404040404040404, 'precision@10': 0.00808080808080808, 'mrr': 0.03493300350443208, 'ndcg@5': 0.011690751135159383, 'ndcg@10': 0.021678546745347697}}, {'data_set': 'medium_multi', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.006802721088435374, 'recall@10': 0.02040816326530612, 'precision@5': 0.0022522522522522522, 'precision@10': 0.006756756756756757, 'mrr': 0.01746031746031746, 'ndcg@5': 0.004845145789623088, 'ndcg@10': 0.010933376807474382}}, {'data_set': 'medium_multi', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.02040816326530612, 'recall@10': 0.04081632653061224, 'precision@5': 0.007425742574257425, 'precision@10': 0.01485148514851485, 'mrr': 0.053015873015873016, 'ndcg@5': 0.01974757800403576, 'ndcg@10': 0.029312817750386008}}, {'data_set': 'medium_multi', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.013605442176870748, 'recall@10': 0.02040816326530612, 'precision@5': 0.0056657223796034, 'precision@10': 0.0084985835694051, 'mrr': 0.02, 'ndcg@5': 0.008593862289975709, 'ndcg@10': 0.01189466446716484}}, {'data_set': 'hard_single', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.05555555555555555, 'recall@10': 0.1111111111111111, 'precision@5': 0.004545454545454545, 'precision@10': 0.00909090909090909, 'mrr': 0.045454545454545456, 'ndcg@5': 0.02787032694388447, 'ndcg@10': 0.06025279849915921}}, {'data_set': 'hard_single', 'retrieval': 'bm25', 'performance': {'recall@5': 0.1111111111111111, 'recall@10': 0.1111111111111111, 'precision@5': 0.00909090909090909, 'precision@10': 0.00909090909090909, 'mrr': 0.045454545454545456, 'ndcg@5': 0.06315860733145308, 'ndcg@10': 0.06315860733145308}}, {'data_set': 'hard_single', 'retrieval': 'dense', 'performance': {'recall@5': 0.1111111111111111, 'recall@10': 0.1111111111111111, 'precision@5': 0.0030303030303030303, 'precision@10': 0.0030303030303030303, 'mrr': 0.10909090909090909, 'ndcg@5': 0.10741289023066841, 'ndcg@10': 0.10741289023066841}}, {'data_set': 'hard_single', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.05555555555555555, 'recall@10': 0.05555555555555555, 'precision@5': 0.00625, 'precision@10': 0.00625, 'mrr': 0.09090909090909091, 'ndcg@5': 0.19372088668831433, 'ndcg@10': 0.19372088668831433}}, {'data_set': 'hard_single', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.05555555555555555, 'recall@10': 0.05555555555555555, 'precision@5': 0.007194244604316547, 'precision@10': 0.007194244604316547, 'mrr': 0.09090909090909091, 'ndcg@5': 0.19372088668831433, 'ndcg@10': 0.19372088668831433}}, {'data_set': 'hard_single', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.05555555555555555, 'recall@10': 0.05555555555555555, 'precision@5': 0.007518796992481203, 'precision@10': 0.007518796992481203, 'mrr': 0.045454545454545456, 'ndcg@5': 0.05735725032467796, 'ndcg@10': 0.05735725032467796}}, {'data_set': 'hard_single', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.05555555555555555, 'recall@10': 0.05555555555555555, 'precision@5': 0.008695652173913044, 'precision@10': 0.008695652173913044, 'mrr': 0.09090909090909091, 'ndcg@5': 0.09090909090909091, 'ndcg@10': 0.09090909090909091}}, {'data_set': 'hard_multi', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.08333333333333333, 'recall@10': 0.08333333333333333, 'precision@5': 0.008333333333333333, 'precision@10': 0.008333333333333333, 'mrr': 0.05555555555555555, 'ndcg@5': 0.05109559939712153, 'ndcg@10': 0.05109559939712153}}, {'data_set': 'hard_multi', 'retrieval': 'bm25', 'performance': {'recall@5': 0.041666666666666664, 'recall@10': 0.041666666666666664, 'precision@5': 0.004166666666666667, 'precision@10': 0.004166666666666667, 'mrr': 0.027777777777777776, 'ndcg@5': 0.025547799698560764, 'ndcg@10': 0.025547799698560764}}, {'data_set': 'hard_multi', 'retrieval': 'dense', 'performance': {'recall@5': 0.0, 'recall@10': 0.0, 'precision@5': 0.0, 'precision@10': 0.0, 'mrr': 0.0, 'ndcg@5': 0.0, 'ndcg@10': 0.0}}, {'data_set': 'hard_multi', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.0, 'recall@10': 0.0, 'precision@5': 0.0, 'precision@10': 0.0, 'mrr': 0.0, 'ndcg@5': 0.0, 'ndcg@10': 0.0}}, {'data_set': 'hard_multi', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.0, 'recall@10': 0.0, 'precision@5': 0.0, 'precision@10': 0.0, 'mrr': 0.0, 'ndcg@5': 0.0, 'ndcg@10': 0.0}}, {'data_set': 'hard_multi', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.0, 'recall@10': 0.0, 'precision@5': 0.0, 'precision@10': 0.0, 'mrr': 0.0, 'ndcg@5': 0.0, 'ndcg@10': 0.0}}, {'data_set': 'hard_multi', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.0, 'recall@10': 0.0, 'precision@5': 0.0, 'precision@10': 0.0, 'mrr': 0.0, 'ndcg@5': 0.0, 'ndcg@10': 0.0}}, {'data_set': 'test', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.07092198581560284, 'recall@10': 0.09219858156028368, 'precision@5': 0.006024096385542169, 'precision@10': 0.00783132530120482, 'mrr': 0.07704149933065596, 'ndcg@5': 0.07513686525367662, 'ndcg@10': 0.0863652959673566}}, {'data_set': 'test', 'retrieval': 'bm25', 'performance': {'recall@5': 0.07801418439716312, 'recall@10': 0.12056737588652482, 'precision@5': 0.006626506024096385, 'precision@10': 0.010240963855421687, 'mrr': 0.09369425754967924, 'ndcg@5': 0.09114691312944778, 'ndcg@10': 0.11203317354451774}}, {'data_set': 'test', 'retrieval': 'dense', 'performance': {'recall@5': 0.0425531914893617, 'recall@10': 0.05673758865248227, 'precision@5': 0.0020408163265306124, 'precision@10': 0.0027210884353741495, 'mrr': 0.05249844847647824, 'ndcg@5': 0.045027110294652076, 'ndcg@10': 0.05245475936031123}}, {'data_set': 'test', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.0425531914893617, 'recall@10': 0.06382978723404255, 'precision@5': 0.006952491309385863, 'precision@10': 0.010428736964078795, 'mrr': 0.06817790643091848, 'ndcg@5': 0.06636319360131937, 'ndcg@10': 0.08152091295853581}}, {'data_set': 'test', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.03546099290780142, 'recall@10': 0.05673758865248227, 'precision@5': 0.005917159763313609, 'precision@10': 0.009467455621301775, 'mrr': 0.05655044420104661, 'ndcg@5': 0.05579433438037901, 'ndcg@10': 0.06997607482792381}}, {'data_set': 'test', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.04964539007092199, 'recall@10': 0.06382978723404255, 'precision@5': 0.008917197452229299, 'precision@10': 0.011464968152866241, 'mrr': 0.061746987951807226, 'ndcg@5': 0.0573718012908785, 'ndcg@10': 0.06280694406459147}}, {'data_set': 'test', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.03546099290780142, 'recall@10': 0.07092198581560284, 'precision@5': 0.006587615283267457, 'precision@10': 0.013175230566534914, 'mrr': 0.056855995410212266, 'ndcg@5': 0.04840701880489156, 'ndcg@10': 0.0671578661261778}}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A helper function to load subqueries from a ground truth file.\n",
    "def retrieve_all_subqueries(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        qa_data = json.load(f)\n",
    "    subqueries = []\n",
    "    for item in qa_data:\n",
    "        subqueries.extend(item[\"sub_questions\"])\n",
    "    return subqueries\n",
    "\n",
    "# Define dataset configurations.\n",
    "# For each dataset, specify:\n",
    "#  - \"name\": a short name,\n",
    "#  - \"gt_path\": path to the ground truth QA file,\n",
    "#  - For dense retrieval: \"subqueries\" (list) and \"subquery_index\" (FAISS index file path).\n",
    "datasets = [\n",
    "    {\n",
    "        \"name\": \"easy_single\",\n",
    "        \"gt_path\": os.path.join(QA_PATH, \"easy_single_labeled.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join(QA_PATH, \"easy_single_labeled.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"easy_single_labeled_embeddings.index\"))\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"medium_single\",\n",
    "        \"gt_path\": os.path.join(QA_PATH, \"medium_single_labeled.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join(QA_PATH, \"medium_single_labeled.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"medium_single_labeled_embeddings.index\"))\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"medium_multi\",\n",
    "        \"gt_path\": os.path.join(QA_PATH, \"medium_multi_labeled.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join(QA_PATH, \"medium_multi_labeled.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"medium_multi_labeled_embeddings.index\"))\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"hard_single\",\n",
    "        \"gt_path\": os.path.join(QA_PATH, \"hard_single_labeled.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join(QA_PATH, \"hard_single_labeled.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"hard_single_labeled_embeddings.index\"))\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"hard_multi\",\n",
    "        \"gt_path\": os.path.join(QA_PATH, \"hard_multi_labeled.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join(QA_PATH, \"hard_multi_labeled.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"hard_multi_labeled_embeddings.index\"))\n",
    "        }\n",
    "    },\n",
    "    {   \n",
    "        \"name\": \"test\",\n",
    "        \"gt_path\": os.path.join('./data', \"finetune_test_data_test_size_0.2_random_state_42.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join('./data', \"finetune_test_data_test_size_0.2_random_state_42.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"finetune_test_data_test_size_0.2_random_state_42_embeddings.index\"))\n",
    "        }\n",
    "        \n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Retrieval Methods Configuration\n",
    "#########################################\n",
    "\n",
    "# Create a dictionary mapping retrieval method names to their functions.\n",
    "retrieval_methods = {\n",
    "    \"tfidf\": tfidf_retrieval,\n",
    "    \"bm25\": bm25_retrieval,\n",
    "    \"dense\": dense_retrieval_subqueries,\n",
    "    \"tfidf_dense\": hybrid,\n",
    "    \"bm25_dense\": hybrid,\n",
    "    \"dense_tfidf\": hybrid,\n",
    "    \"dense_bm25\": hybrid,\n",
    "}\n",
    "\n",
    "# For each dataset, define a configuration for each retrieval method.\n",
    "# Here we create a dictionary keyed by retrieval method for each dataset.\n",
    "for ds in datasets:\n",
    "    ds.setdefault(\"retrieval_config\", {})\n",
    "    #TF-IDF configuration.\n",
    "    ds[\"retrieval_config\"][\"tfidf\"] = {\n",
    "        \"passages\": passages,\n",
    "        \"chunk_ids\": chunk_ids,\n",
    "        \"vectorizer\": tfidf_vectorizer,\n",
    "        \"doc_matrix\": doc_matrix,\n",
    "        \"top_k\": 20,\n",
    "        \"query_type\": \"question\"  # or \"sub_questions\" based on your data structure\n",
    "    }\n",
    "    # BM25 configuration.\n",
    "    ds[\"retrieval_config\"][\"bm25\"] = {\n",
    "        \"passages\": passages,\n",
    "        \"chunk_ids\": chunk_ids,\n",
    "        \"bm25\": bm25,\n",
    "        \"top_k\": 20,\n",
    "        \"query_type\": \"question\"  # or \"sub_questions\" based on your data structure\n",
    "    }\n",
    "    #Dense retrieval configuration.\n",
    "    ds[\"retrieval_config\"][\"dense\"] = {\n",
    "        \"passages\": passages,\n",
    "        \"chunk_ids\": chunk_ids,\n",
    "        \"all_subqueries\": ds[\"dense\"][\"subqueries\"],\n",
    "        \"subquery_index\": ds[\"dense\"][\"subquery_index\"],\n",
    "        \"faiss_index\": corpus_dense_index,\n",
    "        \"top_k\": 20,\n",
    "        \"query_type\": \"sub_questions\"  # or \"question\" based on your data structure\n",
    "    }\n",
    "        # --- Add Hybrid Configurations ---\n",
    "    # Hybrid TF-IDF + Dense configuration.\n",
    "    ds[\"retrieval_config\"][\"tfidf_dense\"] = {\n",
    "        \"sparse_func\": tfidf_retrieval,\n",
    "        \"sparse_config\": ds[\"retrieval_config\"][\"tfidf\"],\n",
    "        \"dense_func\": dense_retrieval_subqueries,\n",
    "        \"dense_config\": ds[\"retrieval_config\"][\"dense\"],\n",
    "        \"intermediate_k\": 1000,   # You can choose this value independently.\n",
    "        \"final_k\": 20,           # And choose the final number of results.\n",
    "        \"mode\": \"intersection\" , # or \"union\"\n",
    "        \"query_type\": \"combine\",  # or \"sub_questions\" based on your data structure\n",
    "        \"order\": \"sparse_dense\"  # or \"dense_sparse\"\n",
    "\n",
    "    }\n",
    "    # Hybrid BM25 + Dense configuration.\n",
    "    ds[\"retrieval_config\"][\"bm25_dense\"] = {\n",
    "        \"sparse_func\": bm25_retrieval,\n",
    "        \"sparse_config\": ds[\"retrieval_config\"][\"bm25\"],\n",
    "        \"dense_func\": dense_retrieval_subqueries,\n",
    "        \"dense_config\": ds[\"retrieval_config\"][\"dense\"],\n",
    "        \"intermediate_k\": 1000,\n",
    "        \"final_k\": 20,\n",
    "        \"mode\": \"intersection\" , # or \"union\"\n",
    "        \"query_type\": \"combine\",  # or \"sub_questions\" based on your data structure\n",
    "        \"order\": \"sparse_dense\"  # or \"dense_sparse\"\n",
    "    }\n",
    "    ds[\"retrieval_config\"][\"dense_tfidf\"] = {\n",
    "        \"sparse_func\": tfidf_retrieval,\n",
    "        \"sparse_config\": ds[\"retrieval_config\"][\"tfidf\"],\n",
    "        \"dense_func\": dense_retrieval_subqueries,\n",
    "        \"dense_config\": ds[\"retrieval_config\"][\"dense\"],\n",
    "        \"intermediate_k\": 1000,   # You can choose this value independently.\n",
    "        \"final_k\": 20,           # And choose the final number of results.\n",
    "        \"mode\": \"intersection\" , # or \"union\"\n",
    "        \"query_type\": \"combine\",  # or \"sub_questions\" based on your data structure\n",
    "        \"order\": \"dense_sparse\"  # or \"dense_sparse\"\n",
    "\n",
    "    }\n",
    "    # Hybrid BM25 + Dense configuration.\n",
    "    ds[\"retrieval_config\"][\"dense_bm25\"] = {\n",
    "        \"sparse_func\": bm25_retrieval,\n",
    "        \"sparse_config\": ds[\"retrieval_config\"][\"bm25\"],\n",
    "        \"dense_func\": dense_retrieval_subqueries,\n",
    "        \"dense_config\": ds[\"retrieval_config\"][\"dense\"],\n",
    "        \"intermediate_k\": 1000,\n",
    "        \"final_k\": 20,\n",
    "        \"mode\": \"intersection\" , # or \"union\"\n",
    "        \"query_type\": \"combine\",  # or \"sub_questions\" based on your data structure\n",
    "        \"order\": \"dense_sparse\"  # or \"dense_sparse\"\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Test Process: Evaluate Each Retrieval Method on Each Dataset\n",
    "#########################################\n",
    "# load the results\n",
    "# save_path = os.path.join(QA_PATH, \"retrieval_results_bge_cosine.json\")\n",
    "# with open(save_path, \"r\") as f:\n",
    "#     results = json.load(f)\n",
    "\n",
    "results = []\n",
    "\n",
    "for ds in datasets:\n",
    "    # Load ground truth data.\n",
    "    with open(ds[\"gt_path\"], \"r\", encoding=\"utf-8\") as f:\n",
    "        ground_truth_data = json.load(f)\n",
    "    print(f\"Dataset '{ds['name']}': loaded {len(ground_truth_data)} ground truth examples.\")\n",
    "    \n",
    "    # For each retrieval method defined in this dataset's config:\n",
    "    for method_name, method_func in retrieval_methods.items():\n",
    "        # Check if a configuration exists for this method.\n",
    "        if method_name in ds[\"retrieval_config\"]:\n",
    "            config = ds[\"retrieval_config\"][method_name]\n",
    "            predictions = []\n",
    "            references = []\n",
    "            for example in ground_truth_data:\n",
    "                query_type = config.get(\"query_type\")\n",
    "                query = [example[\"question\"], example[\"sub_questions\"]]\n",
    "                if query_type == \"sub_questions\":\n",
    "                    question = query[1]\n",
    "                elif query_type == \"question\":\n",
    "                    question = query[0]\n",
    "                else:\n",
    "                    question = query \n",
    "                ret_results = method_func(question, config)\n",
    "                # Collect predicted chunk IDs (convert to string).\n",
    "                pred_ids = [str(r[\"chunk_id\"]) for r in ret_results]\n",
    "                predictions.append(pred_ids)\n",
    "                # Ground truth: assume each reference in \"list of reference\" has a \"ref_id\".\n",
    "                gt_ids = [str(ref[\"ref_id\"]) for ref in example[\"list of reference\"]]\n",
    "                references.append(gt_ids)\n",
    "            \n",
    "            # Initialize evaluation metrics.\n",
    "            eval_collection = MetricCollection({\n",
    "                \"recall@5\": RecallAtK(k=5),\n",
    "                \"recall@10\": RecallAtK(k=10),\n",
    "                \"precision@5\": PrecisionAtK(k=5),\n",
    "                \"precision@10\": PrecisionAtK(k=10),\n",
    "                \"mrr\": MRR(),\n",
    "                \"ndcg@5\": nDCG(k=5),\n",
    "                \"ndcg@10\": nDCG(k=10)\n",
    "            })\n",
    "            eval_collection.update(predictions, references, metric_type=\"retrieval\")\n",
    "            overall_metrics = eval_collection.compute(metric_type=\"retrieval\")\n",
    "            \n",
    "            results.append({\n",
    "                \"data_set\": ds[\"name\"],\n",
    "                \"retrieval\": method_name,\n",
    "                \"performance\": overall_metrics\n",
    "            })\n",
    "            print(f\"Evaluated {method_name} on {ds['name']}: {overall_metrics}\")\n",
    "\n",
    "#########################################\n",
    "# Now 'results' contains evaluation metrics for each dataset and each retrieval method.\n",
    "#########################################\n",
    "\n",
    "# Optionally, you can now plot the results. For example, a grouped bar chart comparing methods on each dataset.\n",
    "# (You can adapt your previous plotting code using the results list.)\n",
    "print(\"Final Results:\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./evaluation/retrieval_evaluation/retrieval_results_dpr.json\n"
     ]
    }
   ],
   "source": [
    "# save the results to a JSON file.\n",
    "METRICS_PATH = \"./evaluation/retrieval_evaluation\"\n",
    "save_path = os.path.join(METRICS_PATH, \"retrieval_results_dpr.json\")\n",
    "# Ensure the directory exists.\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "# Save the results to the specified JSON file.\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "# Print a message indicating where the results were saved.\n",
    "print(f\"Results saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
