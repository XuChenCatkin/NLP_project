{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading passages from D:/NLP_Project/NLP_project/data/chunked_text_all_together_cleaned.json\n"
     ]
    }
   ],
   "source": [
    "from evaluation.eval_utils import *\n",
    "from evaluation.eval_utils import *\n",
    "import json\n",
    "from retrieval import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9251 corpus passages\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For text-based retrieval:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Import your evaluation framework.\n",
    "from evaluation.eval_utils import MetricCollection, RecallAtK, PrecisionAtK, MRR, nDCG\n",
    "\n",
    "#########################################\n",
    "# Retrieval Method Functions\n",
    "#########################################\n",
    "\n",
    "def tfidf_retrieval(query, config):\n",
    "    \"\"\"\n",
    "    TF-IDF retrieval.\n",
    "    config must include:\n",
    "      - \"vectorizer\": a fitted TfidfVectorizer,\n",
    "      - \"doc_matrix\": document-term matrix,\n",
    "      - \"passages\": list of passages,\n",
    "      - \"chunk_ids\": list of passage identifiers,\n",
    "      - \"top_k\": number of top results.\n",
    "    \"\"\"\n",
    "    vectorizer = config[\"vectorizer\"]\n",
    "    doc_matrix = config[\"doc_matrix\"]\n",
    "    passages = config[\"passages\"]\n",
    "    chunk_ids = config[\"chunk_ids\"]\n",
    "    top_k = config.get(\"top_k\", 5)\n",
    "    \n",
    "    query_vec = vectorizer.transform([query])\n",
    "    cosine_similarities = (doc_matrix @ query_vec.T).toarray().flatten()\n",
    "    sorted_indices = np.argsort(cosine_similarities)[::-1][:top_k]\n",
    "    \n",
    "    results = [{\"chunk_id\": chunk_ids[i], \"score\": float(cosine_similarities[i])} \n",
    "               for i in sorted_indices]\n",
    "    return results\n",
    "\n",
    "def bm25_retrieval(query, config):\n",
    "    \"\"\"\n",
    "    BM25 retrieval.\n",
    "    config must include:\n",
    "      - \"bm25\": a BM25Okapi object,\n",
    "      - \"passages\": list of passages,\n",
    "      - \"chunk_ids\": list of passage identifiers,\n",
    "      - \"top_k\": number of top results.\n",
    "    \"\"\"\n",
    "    bm25 = config[\"bm25\"]\n",
    "    passages = config[\"passages\"]\n",
    "    chunk_ids = config[\"chunk_ids\"]\n",
    "    top_k = config.get(\"top_k\", 5)\n",
    "    \n",
    "    tokenized_query = word_tokenize(query.lower())\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    sorted_indices = np.argsort(scores)[::-1][:top_k]\n",
    "    \n",
    "    results = [{\"chunk_id\": chunk_ids[i], \"score\": float(scores[i])} \n",
    "               for i in sorted_indices]\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def dense_retrieval_subqueries(queries, config):\n",
    "\n",
    "    if isinstance(queries, str):\n",
    "        queries = [queries]\n",
    "\n",
    "    results = []\n",
    "    top_k = config.get(\"top_k\", 5)\n",
    "    for query in queries:\n",
    "        query_emb = query_embed_search(query, config[\"all_subqueries\"], config[\"subquery_index\"])\n",
    "        query_emb = query_emb.reshape(1, -1)  # Reshape to (1, d)\n",
    "        distances, indices = config[\"faiss_index\"].search(query_emb, top_k)\n",
    "        results.extend([\n",
    "            {\n",
    "                \"sub_query\": query,\n",
    "                \"chunk_id\": config[\"chunk_ids\"][i],\n",
    "                \"passage\": config[\"passages\"][i],\n",
    "                \"score\": float(distances[0][j])\n",
    "            } for j, i in enumerate(indices[0])\n",
    "        ])\n",
    "    return results\n",
    "\n",
    "def query_embed_search(query, all_queries_list, index):\n",
    "    \"\"\"\n",
    "    Given a query, finds its embedding from the precomputed subqueries index.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        position = all_queries_list.index(query)\n",
    "        return index.reconstruct(position)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Query '{query}' not found in the list of all queries.\")\n",
    "    \n",
    "def hybrid(query, config):\n",
    "    \"\"\"\n",
    "    Hybrid retrieval: first uses a sparse retrieval method to get an intermediate set,\n",
    "    then re-ranks candidates using a dense retrieval function and returns the final top-k results.\n",
    "    \n",
    "    Parameters:\n",
    "      - query (str): The input query.\n",
    "      - config (dict): A configuration dictionary containing:\n",
    "            * \"sparse_func\": Function for sparse retrieval (e.g., tfidf_retrieval or bm25_retrieval).\n",
    "            * \"sparse_config\": Dictionary for the sparse retrieval configuration.\n",
    "            * \"dense_func\": Function for dense retrieval (e.g., dense_retrieval_subqueries).\n",
    "            * \"dense_config\": Dictionary for the dense retrieval configuration.\n",
    "            * \"intermediate_k\": Number of candidates to retrieve using the sparse method.\n",
    "            * \"final_k\": Number of final results to return after dense re-ranking.\n",
    "            * \"mode\": \"intersection\" (default) or \"union\".\n",
    "                - \"intersection\": Use only candidates present in the sparse results.\n",
    "                - \"union\": Combine candidates from both sparse and dense retrieval.\n",
    "                \n",
    "    Returns:\n",
    "      A list of dictionaries corresponding to the final top_k results.\n",
    "      Each dictionary includes at least \"chunk_id\" and \"score\" (dense score).\n",
    "    \"\"\"\n",
    "    if isinstance(query, list) and len(query) >= 2:\n",
    "        query_sparse = query[0]\n",
    "        query_dense = query[1]\n",
    "    else:\n",
    "        print(\"Query should be a list of two queries: [sparse_query, dense_query].\")\n",
    "    intermediate_k = config.get(\"intermediate_k\")\n",
    "    final_k = config.get(\"final_k\")\n",
    "    mode = config.get(\"mode\", \"intersection\")\n",
    "    \n",
    "    # Retrieve intermediate candidate set using the sparse retrieval function.\n",
    "    sparse_config = config[\"sparse_config\"].copy()\n",
    "    sparse_config[\"top_k\"] = intermediate_k\n",
    "    sparse_results = config[\"sparse_func\"](query_sparse, sparse_config)\n",
    "    \n",
    "    \n",
    "    # Retrieve dense results using the dense retrieval function.\n",
    "    dense_results = config[\"dense_func\"](query_dense, config[\"dense_config\"])\n",
    "    \n",
    "    if mode == \"intersection\":\n",
    "        # Use only candidates that appear in the sparse results.\n",
    "        candidate_ids = set(r[\"chunk_id\"] for r in sparse_results)\n",
    "        filtered_dense = [r for r in dense_results if r[\"chunk_id\"] in candidate_ids]\n",
    "        if not filtered_dense:\n",
    "            # If no overlap, fall back to all dense results.\n",
    "            filtered_dense = dense_results\n",
    "    elif mode == \"union\":\n",
    "        # Use the union of candidate IDs from sparse and dense retrieval.\n",
    "        candidate_ids = set(r[\"chunk_id\"] for r in sparse_results).union(\n",
    "                        set(r[\"chunk_id\"] for r in dense_results))\n",
    "        # Build a dictionary for dense results (using dense score), with default 0 if not present.\n",
    "        dense_dict = {r[\"chunk_id\"]: r for r in dense_results}\n",
    "        filtered_dense = []\n",
    "        for cid in candidate_ids:\n",
    "            if cid in dense_dict:\n",
    "                filtered_dense.append(dense_dict[cid])\n",
    "            else:\n",
    "                # If candidate from sparse isn't in dense, create a dummy entry with 0 score.\n",
    "                filtered_dense.append({\"chunk_id\": cid, \"score\": 0.0})\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Choose 'intersection' or 'union'.\")\n",
    "    \n",
    "    # Sort the filtered dense results by their dense score (highest first).\n",
    "    sorted_dense = sorted(filtered_dense, key=lambda x: x[\"score\"], reverse=True)\n",
    "    final_results = sorted_dense[:final_k]\n",
    "    return final_results\n",
    "def hybrid(query, config):\n",
    "    \"\"\"\n",
    "    Hybrid retrieval: first retrieve candidates with one method, then re-rank with the other.\n",
    "    \n",
    "    The order is determined by config[\"order\"]:\n",
    "      - \"sparse_dense\" (default): Use query[0] (or query if not a list) for sparse retrieval,\n",
    "                                   then query[1] (or query) for dense retrieval.\n",
    "      - \"dense_sparse\": Use query[0] for dense retrieval,\n",
    "                        then query[1] for sparse retrieval.\n",
    "    \n",
    "    The candidate sets are combined (using the \"mode\": \"intersection\" or \"union\")\n",
    "    and then sorted by the score of the re-ranking model.\n",
    "    \n",
    "    Parameters:\n",
    "      - query (str or list): If a list of at least two elements, the two parts will be used\n",
    "                             in the order specified by config[\"order\"]. Otherwise, the same query is used.\n",
    "      - config (dict): Must contain:\n",
    "          * \"order\": either \"sparse_dense\" (default) or \"dense_sparse\"\n",
    "          * \"sparse_func\": sparse retrieval function (e.g., tfidf_retrieval or bm25_retrieval)\n",
    "          * \"sparse_config\": configuration for the sparse method.\n",
    "          * \"dense_func\": dense retrieval function (e.g., dense_retrieval_subqueries)\n",
    "          * \"dense_config\": configuration for the dense method.\n",
    "          * \"intermediate_k\": candidate set size (default: 30)\n",
    "          * \"final_k\": final result count (default: 5)\n",
    "          * \"mode\": \"intersection\" (default) or \"union\"\n",
    "    \n",
    "    Returns:\n",
    "      A list of final results (dictionaries) from the re-ranking step.\n",
    "    \"\"\"\n",
    "    order = config.get(\"order\", \"sparse_dense\")\n",
    "    intermediate_k = config.get(\"intermediate_k\", 30)\n",
    "    final_k = config.get(\"final_k\", 5)\n",
    "    mode = config.get(\"mode\", \"intersection\")\n",
    "    \n",
    "    # Decide which query part to use for each retrieval step.\n",
    "    if isinstance(query, list) and len(query) >= 2:\n",
    "        query_sparse = query[0]\n",
    "        query_dense = query[1]\n",
    "    else:\n",
    "        print(\"Query should be a list of two queries: [sparse_query, dense_query].\")\n",
    "\n",
    "\n",
    "    if order == \"sparse_dense\":\n",
    "        # Sparse retrieval first.\n",
    "        sparse_config = config[\"sparse_config\"].copy()\n",
    "        sparse_config[\"top_k\"] = intermediate_k\n",
    "        sparse_results = config[\"sparse_func\"](query_sparse, sparse_config)\n",
    "        \n",
    "        # Dense retrieval.\n",
    "        dense_results = config[\"dense_func\"](query_dense, config[\"dense_config\"])\n",
    "        \n",
    "        # Combine: here we choose to filter dense results by the candidate set from sparse.\n",
    "        candidate_ids = set(r[\"chunk_id\"] for r in sparse_results)\n",
    "        filtered_dense = [r for r in dense_results if r[\"chunk_id\"] in candidate_ids]\n",
    "        if not filtered_dense:\n",
    "            filtered_dense = dense_results\n",
    "        # Sort by dense score.\n",
    "        sorted_results = sorted(filtered_dense, key=lambda x: x[\"score\"], reverse=True)\n",
    "    \n",
    "    elif order == \"dense_sparse\":\n",
    "        # Dense retrieval first.\n",
    "        dense_results = config[\"dense_func\"](query_dense, config[\"dense_config\"])\n",
    "        # Sparse retrieval.\n",
    "        sparse_config = config[\"sparse_config\"].copy()\n",
    "        sparse_config[\"top_k\"] = intermediate_k\n",
    "        sparse_results = config[\"sparse_func\"](query_sparse, sparse_config)\n",
    "        # Combine: filter sparse results by dense candidate set.\n",
    "        candidate_ids = set(r[\"chunk_id\"] for r in dense_results)\n",
    "        filtered_sparse = [r for r in sparse_results if r[\"chunk_id\"] in candidate_ids]\n",
    "        if not filtered_sparse:\n",
    "            filtered_sparse = sparse_results\n",
    "        # Sort by sparse score.\n",
    "        sorted_results = sorted(filtered_sparse, key=lambda x: x[\"score\"], reverse=True)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid order specified.\")\n",
    "    \n",
    "    return sorted_results[:final_k]\n",
    "\n",
    "#########################################\n",
    "# Dataset Configuration\n",
    "#########################################\n",
    "\n",
    "# Global corpus (for all retrieval methods that use it).\n",
    "def load_corpus(corpus_file):\n",
    "    with open(corpus_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    passages = [entry[\"passage\"] for entry in data if \"passage\" in entry]\n",
    "    chunk_ids = [entry[\"chunk_id\"] for entry in data if \"chunk_id\" in entry]\n",
    "    print(f\"Loaded {len(passages)} corpus passages\")\n",
    "    return passages, chunk_ids\n",
    "\n",
    "# Paths for the corpus and QA sets.\n",
    "CORPUS_FILE = \"./data/chunked_text_all_together_cleaned.json\"\n",
    "QA_PATH = \"./data/QA_set\"\n",
    "QA_EMBEDDED_PATH = \"./embedding/BAAI/bge-base-en-v1.5_finetuned\"\n",
    "\n",
    "# Load the corpus and build common indexes.\n",
    "passages, chunk_ids = load_corpus(CORPUS_FILE)\n",
    "\n",
    "# Build TF-IDF index for the corpus.\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "doc_matrix = tfidf_vectorizer.fit_transform(passages)\n",
    "\n",
    "# Build BM25 index for the corpus.\n",
    "tokenized_passages = [word_tokenize(p.lower()) for p in passages]\n",
    "bm25 = BM25Okapi(tokenized_passages)\n",
    "\n",
    "# Load global dense corpus index (FAISS).\n",
    "corpus_dense_index = faiss.read_index(\"embedding/BAAI/bge-base-en-v1.5_finetuned/hp_all_BAAI/bge-base-en-v1.5_finetuned.index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'easy_single': loaded 253 ground truth examples.\n",
      "Evaluated tfidf on easy_single: {'recall@5': 0.08389261744966443, 'recall@10': 0.12416107382550336, 'precision@5': 0.004940711462450593, 'precision@10': 0.007312252964426878, 'mrr': 0.0647274655644802, 'ndcg@5': 0.05913122106512458, 'ndcg@10': 0.07361285003547607}\n",
      "Evaluated bm25 on easy_single: {'recall@5': 0.08389261744966443, 'recall@10': 0.15436241610738255, 'precision@5': 0.004940711462450593, 'precision@10': 0.00909090909090909, 'mrr': 0.0636334769291915, 'ndcg@5': 0.05909196015880151, 'ndcg@10': 0.08244786017469655}\n",
      "Evaluated dense on easy_single: {'recall@5': 0.6208053691275168, 'recall@10': 0.714765100671141, 'precision@5': 0.036561264822134384, 'precision@10': 0.04209486166007905, 'mrr': 0.5650399093510547, 'ndcg@5': 0.5468185644673524, 'ndcg@10': 0.5752865016109433}\n",
      "Evaluated tfidf_dense on easy_single: {'recall@5': 0.4261744966442953, 'recall@10': 0.48322147651006714, 'precision@5': 0.03988693467336683, 'precision@10': 0.04522613065326633, 'mrr': 0.4139598395352871, 'ndcg@5': 0.3986996366103936, 'ndcg@10': 0.41617676539764253}\n",
      "Evaluated bm25_dense on easy_single: {'recall@5': 0.3859060402684564, 'recall@10': 0.4161073825503356, 'precision@5': 0.04693877551020408, 'precision@10': 0.05061224489795919, 'mrr': 0.3726194166731252, 'ndcg@5': 0.36423770732477845, 'ndcg@10': 0.3736860876168736}\n",
      "Evaluated dense_tfidf on easy_single: {'recall@5': 0.26174496644295303, 'recall@10': 0.37583892617449666, 'precision@5': 0.024497487437185928, 'precision@10': 0.035175879396984924, 'mrr': 0.1760662329535544, 'ndcg@5': 0.17410894783295852, 'ndcg@10': 0.21127862344843318}\n",
      "Evaluated dense_bm25 on easy_single: {'recall@5': 0.27181208053691275, 'recall@10': 0.3624161073825503, 'precision@5': 0.03306122448979592, 'precision@10': 0.044081632653061226, 'mrr': 0.18376742383659395, 'ndcg@5': 0.18798766208386375, 'ndcg@10': 0.22009176155701166}\n",
      "Dataset 'medium_single': loaded 91 ground truth examples.\n",
      "Evaluated tfidf on medium_single: {'recall@5': 0.136, 'recall@10': 0.184, 'precision@5': 0.00934065934065934, 'precision@10': 0.012637362637362638, 'mrr': 0.1221554696829422, 'ndcg@5': 0.1106424051223992, 'ndcg@10': 0.12665075284931043}\n",
      "Evaluated bm25 on medium_single: {'recall@5': 0.12, 'recall@10': 0.16, 'precision@5': 0.008241758241758242, 'precision@10': 0.01098901098901099, 'mrr': 0.11703980743888205, 'ndcg@5': 0.11453206515215979, 'ndcg@10': 0.1288959184344231}\n",
      "Evaluated dense on medium_single: {'recall@5': 0.544, 'recall@10': 0.632, 'precision@5': 0.012454212454212455, 'precision@10': 0.01446886446886447, 'mrr': 0.4770440754434122, 'ndcg@5': 0.48882954573289183, 'ndcg@10': 0.5120623194623214}\n",
      "Evaluated tfidf_dense on medium_single: {'recall@5': 0.416, 'recall@10': 0.488, 'precision@5': 0.029885057471264367, 'precision@10': 0.03505747126436782, 'mrr': 0.42272141777636274, 'ndcg@5': 0.5877268847993444, 'ndcg@10': 0.6708018826503942}\n",
      "Evaluated bm25_dense on medium_single: {'recall@5': 0.4, 'recall@10': 0.448, 'precision@5': 0.029726516052318668, 'precision@10': 0.03329369797859691, 'mrr': 0.42782725516242, 'ndcg@5': 0.5943141503742569, 'ndcg@10': 0.6657826938441523}\n",
      "Evaluated dense_tfidf on medium_single: {'recall@5': 0.24, 'recall@10': 0.344, 'precision@5': 0.01852995676343422, 'precision@10': 0.026559604694255712, 'mrr': 0.23820618684701972, 'ndcg@5': 0.19277633495027793, 'ndcg@10': 0.23484271358895842}\n",
      "Evaluated dense_bm25 on medium_single: {'recall@5': 0.224, 'recall@10': 0.344, 'precision@5': 0.0190865712338105, 'precision@10': 0.02931152010906612, 'mrr': 0.219266166636714, 'ndcg@5': 0.19289680033163542, 'ndcg@10': 0.23721946252300294}\n",
      "Dataset 'medium_multi': loaded 35 ground truth examples.\n",
      "Evaluated tfidf on medium_multi: {'recall@5': 0.006802721088435374, 'recall@10': 0.006802721088435374, 'precision@5': 0.0014285714285714286, 'precision@10': 0.0014285714285714286, 'mrr': 0.03211600429645542, 'ndcg@5': 0.017518491221870238, 'ndcg@10': 0.017518491221870238}\n",
      "Evaluated bm25 on medium_multi: {'recall@5': 0.027210884353741496, 'recall@10': 0.04081632653061224, 'precision@5': 0.005714285714285714, 'precision@10': 0.008571428571428572, 'mrr': 0.06294610151753008, 'ndcg@5': 0.03288943101954012, 'ndcg@10': 0.03629333292455425}\n",
      "Evaluated dense on medium_multi: {'recall@5': 0.22448979591836735, 'recall@10': 0.29931972789115646, 'precision@5': 0.015714285714285715, 'precision@10': 0.02095238095238095, 'mrr': 0.5272304136965791, 'ndcg@5': 0.3122409420021688, 'ndcg@10': 0.33699226998390136}\n",
      "Evaluated tfidf_dense on medium_multi: {'recall@5': 0.14285714285714285, 'recall@10': 0.1836734693877551, 'precision@5': 0.032357473035439135, 'precision@10': 0.04160246533127889, 'mrr': 0.45889848246991105, 'ndcg@5': 0.2695304388250594, 'ndcg@10': 0.30263595466035303}\n",
      "Evaluated bm25_dense on medium_multi: {'recall@5': 0.14965986394557823, 'recall@10': 0.1564625850340136, 'precision@5': 0.034482758620689655, 'precision@10': 0.03605015673981191, 'mrr': 0.4578904428904429, 'ndcg@5': 0.32001522819687, 'ndcg@10': 0.3256785675632684}\n",
      "Evaluated dense_tfidf on medium_multi: {'recall@5': 0.07482993197278912, 'recall@10': 0.1292517006802721, 'precision@5': 0.01854974704890388, 'precision@10': 0.03204047217537943, 'mrr': 0.21118048618048618, 'ndcg@5': 0.09325600481088547, 'ndcg@10': 0.11746290349075385}\n",
      "Evaluated dense_bm25 on medium_multi: {'recall@5': 0.09523809523809523, 'recall@10': 0.16326530612244897, 'precision@5': 0.02578268876611418, 'precision@10': 0.04419889502762431, 'mrr': 0.3007401725258868, 'ndcg@5': 0.1390145135569154, 'ndcg@10': 0.16623566347179444}\n",
      "Dataset 'hard_single': loaded 11 ground truth examples.\n",
      "Evaluated tfidf on hard_single: {'recall@5': 0.05555555555555555, 'recall@10': 0.1111111111111111, 'precision@5': 0.004545454545454545, 'precision@10': 0.00909090909090909, 'mrr': 0.045454545454545456, 'ndcg@5': 0.02787032694388447, 'ndcg@10': 0.06025279849915921}\n",
      "Evaluated bm25 on hard_single: {'recall@5': 0.1111111111111111, 'recall@10': 0.1111111111111111, 'precision@5': 0.00909090909090909, 'precision@10': 0.00909090909090909, 'mrr': 0.045454545454545456, 'ndcg@5': 0.06315860733145308, 'ndcg@10': 0.06315860733145308}\n",
      "Evaluated dense on hard_single: {'recall@5': 0.3333333333333333, 'recall@10': 0.5, 'precision@5': 0.00909090909090909, 'precision@10': 0.013636363636363636, 'mrr': 0.41450216450216454, 'ndcg@5': 0.32922656093144725, 'ndcg@10': 0.3797827926891069}\n",
      "Evaluated tfidf_dense on hard_single: {'recall@5': 0.3333333333333333, 'recall@10': 0.3333333333333333, 'precision@5': 0.033707865168539325, 'precision@10': 0.033707865168539325, 'mrr': 0.41558441558441556, 'ndcg@5': 0.35128874462907106, 'ndcg@10': 0.3917879326586595}\n",
      "Evaluated bm25_dense on hard_single: {'recall@5': 0.2222222222222222, 'recall@10': 0.3333333333333333, 'precision@5': 0.026490066225165563, 'precision@10': 0.039735099337748346, 'mrr': 0.3428571428571429, 'ndcg@5': 0.2921232429417884, 'ndcg@10': 0.3570124816752633}\n",
      "Evaluated dense_tfidf on hard_single: {'recall@5': 0.1111111111111111, 'recall@10': 0.3333333333333333, 'precision@5': 0.012658227848101266, 'precision@10': 0.0379746835443038, 'mrr': 0.12002458325987737, 'ndcg@5': 0.053541832157735385, 'ndcg@10': 0.1430440637858192}\n",
      "Evaluated dense_bm25 on hard_single: {'recall@5': 0.16666666666666666, 'recall@10': 0.3333333333333333, 'precision@5': 0.025210084033613446, 'precision@10': 0.05042016806722689, 'mrr': 0.14556277056277056, 'ndcg@5': 0.09899637761228085, 'ndcg@10': 0.19036050463292487}\n",
      "Dataset 'hard_multi': loaded 12 ground truth examples.\n",
      "Evaluated tfidf on hard_multi: {'recall@5': 0.08333333333333333, 'recall@10': 0.08333333333333333, 'precision@5': 0.008333333333333333, 'precision@10': 0.008333333333333333, 'mrr': 0.05555555555555555, 'ndcg@5': 0.05109559939712153, 'ndcg@10': 0.05109559939712153}\n",
      "Evaluated bm25 on hard_multi: {'recall@5': 0.041666666666666664, 'recall@10': 0.041666666666666664, 'precision@5': 0.004166666666666667, 'precision@10': 0.004166666666666667, 'mrr': 0.027777777777777776, 'ndcg@5': 0.025547799698560764, 'ndcg@10': 0.025547799698560764}\n",
      "Evaluated dense on hard_multi: {'recall@5': 0.125, 'recall@10': 0.20833333333333334, 'precision@5': 0.004166666666666667, 'precision@10': 0.006944444444444444, 'mrr': 0.14018817204301073, 'ndcg@5': 0.09286775234227879, 'ndcg@10': 0.12528092687294998}\n",
      "Evaluated tfidf_dense on hard_multi: {'recall@5': 0.08333333333333333, 'recall@10': 0.125, 'precision@5': 0.00851063829787234, 'precision@10': 0.01276595744680851, 'mrr': 0.10555555555555556, 'ndcg@5': 0.07086207546122955, 'ndcg@10': 0.1231264281274909}\n",
      "Evaluated bm25_dense on hard_multi: {'recall@5': 0.041666666666666664, 'recall@10': 0.08333333333333333, 'precision@5': 0.0045662100456621, 'precision@10': 0.0091324200913242, 'mrr': 0.0994047619047619, 'ndcg@5': 0.05109559939712153, 'ndcg@10': 0.08632808559767573}\n",
      "Evaluated dense_tfidf on hard_multi: {'recall@5': 0.125, 'recall@10': 0.125, 'precision@5': 0.013513513513513514, 'precision@10': 0.013513513513513514, 'mrr': 0.1574074074074074, 'ndcg@5': 0.1088811330318941, 'ndcg@10': 0.1088811330318941}\n",
      "Evaluated dense_bm25 on hard_multi: {'recall@5': 0.08333333333333333, 'recall@10': 0.125, 'precision@5': 0.011834319526627219, 'precision@10': 0.01775147928994083, 'mrr': 0.11590909090909092, 'ndcg@5': 0.07086207546122955, 'ndcg@10': 0.08563201602656685}\n",
      "Final Results:\n",
      "[{'data_set': 'easy_single', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.08389261744966443, 'recall@10': 0.12416107382550336, 'precision@5': 0.004940711462450593, 'precision@10': 0.007312252964426878, 'mrr': 0.0647274655644802, 'ndcg@5': 0.05913122106512458, 'ndcg@10': 0.07361285003547607}}, {'data_set': 'easy_single', 'retrieval': 'bm25', 'performance': {'recall@5': 0.08389261744966443, 'recall@10': 0.15436241610738255, 'precision@5': 0.004940711462450593, 'precision@10': 0.00909090909090909, 'mrr': 0.0636334769291915, 'ndcg@5': 0.05909196015880151, 'ndcg@10': 0.08244786017469655}}, {'data_set': 'easy_single', 'retrieval': 'dense', 'performance': {'recall@5': 0.6208053691275168, 'recall@10': 0.714765100671141, 'precision@5': 0.036561264822134384, 'precision@10': 0.04209486166007905, 'mrr': 0.5650399093510547, 'ndcg@5': 0.5468185644673524, 'ndcg@10': 0.5752865016109433}}, {'data_set': 'easy_single', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.4261744966442953, 'recall@10': 0.48322147651006714, 'precision@5': 0.03988693467336683, 'precision@10': 0.04522613065326633, 'mrr': 0.4139598395352871, 'ndcg@5': 0.3986996366103936, 'ndcg@10': 0.41617676539764253}}, {'data_set': 'easy_single', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.3859060402684564, 'recall@10': 0.4161073825503356, 'precision@5': 0.04693877551020408, 'precision@10': 0.05061224489795919, 'mrr': 0.3726194166731252, 'ndcg@5': 0.36423770732477845, 'ndcg@10': 0.3736860876168736}}, {'data_set': 'easy_single', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.26174496644295303, 'recall@10': 0.37583892617449666, 'precision@5': 0.024497487437185928, 'precision@10': 0.035175879396984924, 'mrr': 0.1760662329535544, 'ndcg@5': 0.17410894783295852, 'ndcg@10': 0.21127862344843318}}, {'data_set': 'easy_single', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.27181208053691275, 'recall@10': 0.3624161073825503, 'precision@5': 0.03306122448979592, 'precision@10': 0.044081632653061226, 'mrr': 0.18376742383659395, 'ndcg@5': 0.18798766208386375, 'ndcg@10': 0.22009176155701166}}, {'data_set': 'medium_single', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.136, 'recall@10': 0.184, 'precision@5': 0.00934065934065934, 'precision@10': 0.012637362637362638, 'mrr': 0.1221554696829422, 'ndcg@5': 0.1106424051223992, 'ndcg@10': 0.12665075284931043}}, {'data_set': 'medium_single', 'retrieval': 'bm25', 'performance': {'recall@5': 0.12, 'recall@10': 0.16, 'precision@5': 0.008241758241758242, 'precision@10': 0.01098901098901099, 'mrr': 0.11703980743888205, 'ndcg@5': 0.11453206515215979, 'ndcg@10': 0.1288959184344231}}, {'data_set': 'medium_single', 'retrieval': 'dense', 'performance': {'recall@5': 0.544, 'recall@10': 0.632, 'precision@5': 0.012454212454212455, 'precision@10': 0.01446886446886447, 'mrr': 0.4770440754434122, 'ndcg@5': 0.48882954573289183, 'ndcg@10': 0.5120623194623214}}, {'data_set': 'medium_single', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.416, 'recall@10': 0.488, 'precision@5': 0.029885057471264367, 'precision@10': 0.03505747126436782, 'mrr': 0.42272141777636274, 'ndcg@5': 0.5877268847993444, 'ndcg@10': 0.6708018826503942}}, {'data_set': 'medium_single', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.4, 'recall@10': 0.448, 'precision@5': 0.029726516052318668, 'precision@10': 0.03329369797859691, 'mrr': 0.42782725516242, 'ndcg@5': 0.5943141503742569, 'ndcg@10': 0.6657826938441523}}, {'data_set': 'medium_single', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.24, 'recall@10': 0.344, 'precision@5': 0.01852995676343422, 'precision@10': 0.026559604694255712, 'mrr': 0.23820618684701972, 'ndcg@5': 0.19277633495027793, 'ndcg@10': 0.23484271358895842}}, {'data_set': 'medium_single', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.224, 'recall@10': 0.344, 'precision@5': 0.0190865712338105, 'precision@10': 0.02931152010906612, 'mrr': 0.219266166636714, 'ndcg@5': 0.19289680033163542, 'ndcg@10': 0.23721946252300294}}, {'data_set': 'medium_multi', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.006802721088435374, 'recall@10': 0.006802721088435374, 'precision@5': 0.0014285714285714286, 'precision@10': 0.0014285714285714286, 'mrr': 0.03211600429645542, 'ndcg@5': 0.017518491221870238, 'ndcg@10': 0.017518491221870238}}, {'data_set': 'medium_multi', 'retrieval': 'bm25', 'performance': {'recall@5': 0.027210884353741496, 'recall@10': 0.04081632653061224, 'precision@5': 0.005714285714285714, 'precision@10': 0.008571428571428572, 'mrr': 0.06294610151753008, 'ndcg@5': 0.03288943101954012, 'ndcg@10': 0.03629333292455425}}, {'data_set': 'medium_multi', 'retrieval': 'dense', 'performance': {'recall@5': 0.22448979591836735, 'recall@10': 0.29931972789115646, 'precision@5': 0.015714285714285715, 'precision@10': 0.02095238095238095, 'mrr': 0.5272304136965791, 'ndcg@5': 0.3122409420021688, 'ndcg@10': 0.33699226998390136}}, {'data_set': 'medium_multi', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.14285714285714285, 'recall@10': 0.1836734693877551, 'precision@5': 0.032357473035439135, 'precision@10': 0.04160246533127889, 'mrr': 0.45889848246991105, 'ndcg@5': 0.2695304388250594, 'ndcg@10': 0.30263595466035303}}, {'data_set': 'medium_multi', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.14965986394557823, 'recall@10': 0.1564625850340136, 'precision@5': 0.034482758620689655, 'precision@10': 0.03605015673981191, 'mrr': 0.4578904428904429, 'ndcg@5': 0.32001522819687, 'ndcg@10': 0.3256785675632684}}, {'data_set': 'medium_multi', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.07482993197278912, 'recall@10': 0.1292517006802721, 'precision@5': 0.01854974704890388, 'precision@10': 0.03204047217537943, 'mrr': 0.21118048618048618, 'ndcg@5': 0.09325600481088547, 'ndcg@10': 0.11746290349075385}}, {'data_set': 'medium_multi', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.09523809523809523, 'recall@10': 0.16326530612244897, 'precision@5': 0.02578268876611418, 'precision@10': 0.04419889502762431, 'mrr': 0.3007401725258868, 'ndcg@5': 0.1390145135569154, 'ndcg@10': 0.16623566347179444}}, {'data_set': 'hard_single', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.05555555555555555, 'recall@10': 0.1111111111111111, 'precision@5': 0.004545454545454545, 'precision@10': 0.00909090909090909, 'mrr': 0.045454545454545456, 'ndcg@5': 0.02787032694388447, 'ndcg@10': 0.06025279849915921}}, {'data_set': 'hard_single', 'retrieval': 'bm25', 'performance': {'recall@5': 0.1111111111111111, 'recall@10': 0.1111111111111111, 'precision@5': 0.00909090909090909, 'precision@10': 0.00909090909090909, 'mrr': 0.045454545454545456, 'ndcg@5': 0.06315860733145308, 'ndcg@10': 0.06315860733145308}}, {'data_set': 'hard_single', 'retrieval': 'dense', 'performance': {'recall@5': 0.3333333333333333, 'recall@10': 0.5, 'precision@5': 0.00909090909090909, 'precision@10': 0.013636363636363636, 'mrr': 0.41450216450216454, 'ndcg@5': 0.32922656093144725, 'ndcg@10': 0.3797827926891069}}, {'data_set': 'hard_single', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.3333333333333333, 'recall@10': 0.3333333333333333, 'precision@5': 0.033707865168539325, 'precision@10': 0.033707865168539325, 'mrr': 0.41558441558441556, 'ndcg@5': 0.35128874462907106, 'ndcg@10': 0.3917879326586595}}, {'data_set': 'hard_single', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.2222222222222222, 'recall@10': 0.3333333333333333, 'precision@5': 0.026490066225165563, 'precision@10': 0.039735099337748346, 'mrr': 0.3428571428571429, 'ndcg@5': 0.2921232429417884, 'ndcg@10': 0.3570124816752633}}, {'data_set': 'hard_single', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.1111111111111111, 'recall@10': 0.3333333333333333, 'precision@5': 0.012658227848101266, 'precision@10': 0.0379746835443038, 'mrr': 0.12002458325987737, 'ndcg@5': 0.053541832157735385, 'ndcg@10': 0.1430440637858192}}, {'data_set': 'hard_single', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.16666666666666666, 'recall@10': 0.3333333333333333, 'precision@5': 0.025210084033613446, 'precision@10': 0.05042016806722689, 'mrr': 0.14556277056277056, 'ndcg@5': 0.09899637761228085, 'ndcg@10': 0.19036050463292487}}, {'data_set': 'hard_multi', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.08333333333333333, 'recall@10': 0.08333333333333333, 'precision@5': 0.008333333333333333, 'precision@10': 0.008333333333333333, 'mrr': 0.05555555555555555, 'ndcg@5': 0.05109559939712153, 'ndcg@10': 0.05109559939712153}}, {'data_set': 'hard_multi', 'retrieval': 'bm25', 'performance': {'recall@5': 0.041666666666666664, 'recall@10': 0.041666666666666664, 'precision@5': 0.004166666666666667, 'precision@10': 0.004166666666666667, 'mrr': 0.027777777777777776, 'ndcg@5': 0.025547799698560764, 'ndcg@10': 0.025547799698560764}}, {'data_set': 'hard_multi', 'retrieval': 'dense', 'performance': {'recall@5': 0.125, 'recall@10': 0.20833333333333334, 'precision@5': 0.004166666666666667, 'precision@10': 0.006944444444444444, 'mrr': 0.14018817204301073, 'ndcg@5': 0.09286775234227879, 'ndcg@10': 0.12528092687294998}}, {'data_set': 'hard_multi', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.08333333333333333, 'recall@10': 0.125, 'precision@5': 0.00851063829787234, 'precision@10': 0.01276595744680851, 'mrr': 0.10555555555555556, 'ndcg@5': 0.07086207546122955, 'ndcg@10': 0.1231264281274909}}, {'data_set': 'hard_multi', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.041666666666666664, 'recall@10': 0.08333333333333333, 'precision@5': 0.0045662100456621, 'precision@10': 0.0091324200913242, 'mrr': 0.0994047619047619, 'ndcg@5': 0.05109559939712153, 'ndcg@10': 0.08632808559767573}}, {'data_set': 'hard_multi', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.125, 'recall@10': 0.125, 'precision@5': 0.013513513513513514, 'precision@10': 0.013513513513513514, 'mrr': 0.1574074074074074, 'ndcg@5': 0.1088811330318941, 'ndcg@10': 0.1088811330318941}}, {'data_set': 'hard_multi', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.08333333333333333, 'recall@10': 0.125, 'precision@5': 0.011834319526627219, 'precision@10': 0.01775147928994083, 'mrr': 0.11590909090909092, 'ndcg@5': 0.07086207546122955, 'ndcg@10': 0.08563201602656685}}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A helper function to load subqueries from a ground truth file.\n",
    "def retrieve_all_subqueries(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        qa_data = json.load(f)\n",
    "    subqueries = []\n",
    "    for item in qa_data:\n",
    "        subqueries.extend(item[\"sub_questions\"])\n",
    "    return subqueries\n",
    "\n",
    "# Define dataset configurations.\n",
    "# For each dataset, specify:\n",
    "#  - \"name\": a short name,\n",
    "#  - \"gt_path\": path to the ground truth QA file,\n",
    "#  - For dense retrieval: \"subqueries\" (list) and \"subquery_index\" (FAISS index file path).\n",
    "datasets = [\n",
    "    {\n",
    "        \"name\": \"easy_single\",\n",
    "        \"gt_path\": os.path.join(QA_PATH, \"easy_single_labeled.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join(QA_PATH, \"easy_single_labeled.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"easy_single_labeled_embeddings.index\"))\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"medium_single\",\n",
    "        \"gt_path\": os.path.join(QA_PATH, \"medium_single_labeled.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join(QA_PATH, \"medium_single_labeled.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"medium_single_labeled_embeddings.index\"))\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"medium_multi\",\n",
    "        \"gt_path\": os.path.join(QA_PATH, \"medium_multi_labeled.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join(QA_PATH, \"medium_multi_labeled.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"medium_multi_labeled_embeddings.index\"))\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"hard_single\",\n",
    "        \"gt_path\": os.path.join(QA_PATH, \"hard_single_labeled.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join(QA_PATH, \"hard_single_labeled.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"hard_single_labeled_embeddings.index\"))\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"hard_multi\",\n",
    "        \"gt_path\": os.path.join(QA_PATH, \"hard_multi_labeled.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join(QA_PATH, \"hard_multi_labeled.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"hard_multi_labeled_embeddings.index\"))\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Retrieval Methods Configuration\n",
    "#########################################\n",
    "\n",
    "# Create a dictionary mapping retrieval method names to their functions.\n",
    "retrieval_methods = {\n",
    "    \"tfidf\": tfidf_retrieval,\n",
    "    \"bm25\": bm25_retrieval,\n",
    "    \"dense\": dense_retrieval_subqueries,\n",
    "    \"tfidf_dense\": hybrid,\n",
    "    \"bm25_dense\": hybrid,\n",
    "    \"dense_tfidf\": hybrid,\n",
    "    \"dense_bm25\": hybrid,\n",
    "}\n",
    "\n",
    "# For each dataset, define a configuration for each retrieval method.\n",
    "# Here we create a dictionary keyed by retrieval method for each dataset.\n",
    "for ds in datasets:\n",
    "    ds.setdefault(\"retrieval_config\", {})\n",
    "    #TF-IDF configuration.\n",
    "    ds[\"retrieval_config\"][\"tfidf\"] = {\n",
    "        \"passages\": passages,\n",
    "        \"chunk_ids\": chunk_ids,\n",
    "        \"vectorizer\": tfidf_vectorizer,\n",
    "        \"doc_matrix\": doc_matrix,\n",
    "        \"top_k\": 20,\n",
    "        \"query_type\": \"question\"  # or \"sub_questions\" based on your data structure\n",
    "    }\n",
    "    # BM25 configuration.\n",
    "    ds[\"retrieval_config\"][\"bm25\"] = {\n",
    "        \"passages\": passages,\n",
    "        \"chunk_ids\": chunk_ids,\n",
    "        \"bm25\": bm25,\n",
    "        \"top_k\": 20,\n",
    "        \"query_type\": \"question\"  # or \"sub_questions\" based on your data structure\n",
    "    }\n",
    "    #Dense retrieval configuration.\n",
    "    ds[\"retrieval_config\"][\"dense\"] = {\n",
    "        \"passages\": passages,\n",
    "        \"chunk_ids\": chunk_ids,\n",
    "        \"all_subqueries\": ds[\"dense\"][\"subqueries\"],\n",
    "        \"subquery_index\": ds[\"dense\"][\"subquery_index\"],\n",
    "        \"faiss_index\": corpus_dense_index,\n",
    "        \"top_k\": 20,\n",
    "        \"query_type\": \"sub_questions\"  # or \"question\" based on your data structure\n",
    "    }\n",
    "        # --- Add Hybrid Configurations ---\n",
    "    # Hybrid TF-IDF + Dense configuration.\n",
    "    ds[\"retrieval_config\"][\"tfidf_dense\"] = {\n",
    "        \"sparse_func\": tfidf_retrieval,\n",
    "        \"sparse_config\": ds[\"retrieval_config\"][\"tfidf\"],\n",
    "        \"dense_func\": dense_retrieval_subqueries,\n",
    "        \"dense_config\": ds[\"retrieval_config\"][\"dense\"],\n",
    "        \"intermediate_k\": 1000,   # You can choose this value independently.\n",
    "        \"final_k\": 20,           # And choose the final number of results.\n",
    "        \"mode\": \"intersection\" , # or \"union\"\n",
    "        \"query_type\": \"combine\",  # or \"sub_questions\" based on your data structure\n",
    "        \"order\": \"sparse_dense\"  # or \"dense_sparse\"\n",
    "\n",
    "    }\n",
    "    # Hybrid BM25 + Dense configuration.\n",
    "    ds[\"retrieval_config\"][\"bm25_dense\"] = {\n",
    "        \"sparse_func\": bm25_retrieval,\n",
    "        \"sparse_config\": ds[\"retrieval_config\"][\"bm25\"],\n",
    "        \"dense_func\": dense_retrieval_subqueries,\n",
    "        \"dense_config\": ds[\"retrieval_config\"][\"dense\"],\n",
    "        \"intermediate_k\": 1000,\n",
    "        \"final_k\": 20,\n",
    "        \"mode\": \"intersection\" , # or \"union\"\n",
    "        \"query_type\": \"combine\",  # or \"sub_questions\" based on your data structure\n",
    "        \"order\": \"sparse_dense\"  # or \"dense_sparse\"\n",
    "    }\n",
    "    ds[\"retrieval_config\"][\"dense_tfidf\"] = {\n",
    "        \"sparse_func\": tfidf_retrieval,\n",
    "        \"sparse_config\": ds[\"retrieval_config\"][\"tfidf\"],\n",
    "        \"dense_func\": dense_retrieval_subqueries,\n",
    "        \"dense_config\": ds[\"retrieval_config\"][\"dense\"],\n",
    "        \"intermediate_k\": 1000,   # You can choose this value independently.\n",
    "        \"final_k\": 20,           # And choose the final number of results.\n",
    "        \"mode\": \"intersection\" , # or \"union\"\n",
    "        \"query_type\": \"combine\",  # or \"sub_questions\" based on your data structure\n",
    "        \"order\": \"dense_sparse\"  # or \"dense_sparse\"\n",
    "\n",
    "    }\n",
    "    # Hybrid BM25 + Dense configuration.\n",
    "    ds[\"retrieval_config\"][\"dense_bm25\"] = {\n",
    "        \"sparse_func\": bm25_retrieval,\n",
    "        \"sparse_config\": ds[\"retrieval_config\"][\"bm25\"],\n",
    "        \"dense_func\": dense_retrieval_subqueries,\n",
    "        \"dense_config\": ds[\"retrieval_config\"][\"dense\"],\n",
    "        \"intermediate_k\": 1000,\n",
    "        \"final_k\": 20,\n",
    "        \"mode\": \"intersection\" , # or \"union\"\n",
    "        \"query_type\": \"combine\",  # or \"sub_questions\" based on your data structure\n",
    "        \"order\": \"dense_sparse\"  # or \"dense_sparse\"\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Test Process: Evaluate Each Retrieval Method on Each Dataset\n",
    "#########################################\n",
    "# load the results\n",
    "# save_path = os.path.join(QA_PATH, \"retrieval_results_bge_cosine.json\")\n",
    "# with open(save_path, \"r\") as f:\n",
    "#     results = json.load(f)\n",
    "\n",
    "results = []\n",
    "\n",
    "for ds in datasets:\n",
    "    # Load ground truth data.\n",
    "    with open(ds[\"gt_path\"], \"r\", encoding=\"utf-8\") as f:\n",
    "        ground_truth_data = json.load(f)\n",
    "    print(f\"Dataset '{ds['name']}': loaded {len(ground_truth_data)} ground truth examples.\")\n",
    "    \n",
    "    # For each retrieval method defined in this dataset's config:\n",
    "    for method_name, method_func in retrieval_methods.items():\n",
    "        # Check if a configuration exists for this method.\n",
    "        if method_name in ds[\"retrieval_config\"]:\n",
    "            config = ds[\"retrieval_config\"][method_name]\n",
    "            predictions = []\n",
    "            references = []\n",
    "            for example in ground_truth_data:\n",
    "                query_type = config.get(\"query_type\")\n",
    "                query = [example[\"question\"], example[\"sub_questions\"]]\n",
    "                if query_type == \"sub_questions\":\n",
    "                    question = query[1]\n",
    "                elif query_type == \"question\":\n",
    "                    question = query[0]\n",
    "                else:\n",
    "                    question = query \n",
    "                ret_results = method_func(question, config)\n",
    "                # Collect predicted chunk IDs (convert to string).\n",
    "                pred_ids = [str(r[\"chunk_id\"]) for r in ret_results]\n",
    "                predictions.append(pred_ids)\n",
    "                # Ground truth: assume each reference in \"list of reference\" has a \"ref_id\".\n",
    "                gt_ids = [str(ref[\"ref_id\"]) for ref in example[\"list of reference\"]]\n",
    "                references.append(gt_ids)\n",
    "            \n",
    "            # Initialize evaluation metrics.\n",
    "            eval_collection = MetricCollection({\n",
    "                \"recall@5\": RecallAtK(k=5),\n",
    "                \"recall@10\": RecallAtK(k=10),\n",
    "                \"precision@5\": PrecisionAtK(k=5),\n",
    "                \"precision@10\": PrecisionAtK(k=10),\n",
    "                \"mrr\": MRR(),\n",
    "                \"ndcg@5\": nDCG(k=5),\n",
    "                \"ndcg@10\": nDCG(k=10)\n",
    "            })\n",
    "            eval_collection.update(predictions, references, metric_type=\"retrieval\")\n",
    "            overall_metrics = eval_collection.compute(metric_type=\"retrieval\")\n",
    "            \n",
    "            results.append({\n",
    "                \"data_set\": ds[\"name\"],\n",
    "                \"retrieval\": method_name,\n",
    "                \"performance\": overall_metrics\n",
    "            })\n",
    "            print(f\"Evaluated {method_name} on {ds['name']}: {overall_metrics}\")\n",
    "\n",
    "#########################################\n",
    "# Now 'results' contains evaluation metrics for each dataset and each retrieval method.\n",
    "#########################################\n",
    "\n",
    "# Optionally, you can now plot the results. For example, a grouped bar chart comparing methods on each dataset.\n",
    "# (You can adapt your previous plotting code using the results list.)\n",
    "print(\"Final Results:\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./evaluation/retrieval_evaluation/retrieval_results_bge_finetune.json\n"
     ]
    }
   ],
   "source": [
    "# save the results to a JSON file.\n",
    "METRICS_PATH = \"./evaluation/retrieval_evaluation\"\n",
    "save_path = os.path.join(METRICS_PATH, \"retrieval_results_bge_finetune.json\")\n",
    "# Ensure the directory exists.\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "# Save the results to the specified JSON file.\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "# Print a message indicating where the results were saved.\n",
    "print(f\"Results saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
