{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading passages from D:/NLP_Project/NLP_project/data/chunked_text_all_together_cleaned.json\n"
     ]
    }
   ],
   "source": [
    "from evaluation.eval_utils import *\n",
    "from evaluation.eval_utils import *\n",
    "import json\n",
    "from retrieval import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9251 corpus passages\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For text-based retrieval:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Import your evaluation framework.\n",
    "from evaluation.eval_utils import MetricCollection, RecallAtK, PrecisionAtK, MRR, nDCG\n",
    "\n",
    "#########################################\n",
    "# Retrieval Method Functions\n",
    "#########################################\n",
    "\n",
    "def tfidf_retrieval(query, config):\n",
    "    \"\"\"\n",
    "    TF-IDF retrieval.\n",
    "    config must include:\n",
    "      - \"vectorizer\": a fitted TfidfVectorizer,\n",
    "      - \"doc_matrix\": document-term matrix,\n",
    "      - \"passages\": list of passages,\n",
    "      - \"chunk_ids\": list of passage identifiers,\n",
    "      - \"top_k\": number of top results.\n",
    "    \"\"\"\n",
    "    vectorizer = config[\"vectorizer\"]\n",
    "    doc_matrix = config[\"doc_matrix\"]\n",
    "    passages = config[\"passages\"]\n",
    "    chunk_ids = config[\"chunk_ids\"]\n",
    "    top_k = config.get(\"top_k\", 5)\n",
    "    \n",
    "    query_vec = vectorizer.transform([query])\n",
    "    cosine_similarities = (doc_matrix @ query_vec.T).toarray().flatten()\n",
    "    sorted_indices = np.argsort(cosine_similarities)[::-1][:top_k]\n",
    "    \n",
    "    results = [{\"chunk_id\": chunk_ids[i], \"score\": float(cosine_similarities[i])} \n",
    "               for i in sorted_indices]\n",
    "    return results\n",
    "\n",
    "def bm25_retrieval(query, config):\n",
    "    \"\"\"\n",
    "    BM25 retrieval.\n",
    "    config must include:\n",
    "      - \"bm25\": a BM25Okapi object,\n",
    "      - \"passages\": list of passages,\n",
    "      - \"chunk_ids\": list of passage identifiers,\n",
    "      - \"top_k\": number of top results.\n",
    "    \"\"\"\n",
    "    bm25 = config[\"bm25\"]\n",
    "    passages = config[\"passages\"]\n",
    "    chunk_ids = config[\"chunk_ids\"]\n",
    "    top_k = config.get(\"top_k\", 5)\n",
    "    \n",
    "    tokenized_query = word_tokenize(query.lower())\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    sorted_indices = np.argsort(scores)[::-1][:top_k]\n",
    "    \n",
    "    results = [{\"chunk_id\": chunk_ids[i], \"score\": float(scores[i])} \n",
    "               for i in sorted_indices]\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def dense_retrieval_subqueries(queries, config):\n",
    "\n",
    "    if isinstance(queries, str):\n",
    "        queries = [queries]\n",
    "\n",
    "    results = []\n",
    "    top_k = config.get(\"top_k\", 5)\n",
    "    for query in queries:\n",
    "        query_emb = query_embed_search(query, config[\"all_subqueries\"], config[\"subquery_index\"])\n",
    "        query_emb = query_emb.reshape(1, -1)  # Reshape to (1, d)\n",
    "        distances, indices = config[\"faiss_index\"].search(query_emb, top_k)\n",
    "        results.extend([\n",
    "            {\n",
    "                \"sub_query\": query,\n",
    "                \"chunk_id\": config[\"chunk_ids\"][i],\n",
    "                \"passage\": config[\"passages\"][i],\n",
    "                \"score\": float(distances[0][j])\n",
    "            } for j, i in enumerate(indices[0])\n",
    "        ])\n",
    "    return results\n",
    "\n",
    "def query_embed_search(query, all_queries_list, index):\n",
    "    \"\"\"\n",
    "    Given a query, finds its embedding from the precomputed subqueries index.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        position = all_queries_list.index(query)\n",
    "        return index.reconstruct(position)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Query '{query}' not found in the list of all queries.\")\n",
    "    \n",
    "def hybrid(query, config):\n",
    "    \"\"\"\n",
    "    Hybrid retrieval: first uses a sparse retrieval method to get an intermediate set,\n",
    "    then re-ranks candidates using a dense retrieval function and returns the final top-k results.\n",
    "    \n",
    "    Parameters:\n",
    "      - query (str): The input query.\n",
    "      - config (dict): A configuration dictionary containing:\n",
    "            * \"sparse_func\": Function for sparse retrieval (e.g., tfidf_retrieval or bm25_retrieval).\n",
    "            * \"sparse_config\": Dictionary for the sparse retrieval configuration.\n",
    "            * \"dense_func\": Function for dense retrieval (e.g., dense_retrieval_subqueries).\n",
    "            * \"dense_config\": Dictionary for the dense retrieval configuration.\n",
    "            * \"intermediate_k\": Number of candidates to retrieve using the sparse method.\n",
    "            * \"final_k\": Number of final results to return after dense re-ranking.\n",
    "            * \"mode\": \"intersection\" (default) or \"union\".\n",
    "                - \"intersection\": Use only candidates present in the sparse results.\n",
    "                - \"union\": Combine candidates from both sparse and dense retrieval.\n",
    "                \n",
    "    Returns:\n",
    "      A list of dictionaries corresponding to the final top_k results.\n",
    "      Each dictionary includes at least \"chunk_id\" and \"score\" (dense score).\n",
    "    \"\"\"\n",
    "    if isinstance(query, list) and len(query) >= 2:\n",
    "        query_sparse = query[0]\n",
    "        query_dense = query[1]\n",
    "    else:\n",
    "        print(\"Query should be a list of two queries: [sparse_query, dense_query].\")\n",
    "    intermediate_k = config.get(\"intermediate_k\")\n",
    "    final_k = config.get(\"final_k\")\n",
    "    mode = config.get(\"mode\", \"intersection\")\n",
    "    \n",
    "    # Retrieve intermediate candidate set using the sparse retrieval function.\n",
    "    sparse_config = config[\"sparse_config\"].copy()\n",
    "    sparse_config[\"top_k\"] = intermediate_k\n",
    "    sparse_results = config[\"sparse_func\"](query_sparse, sparse_config)\n",
    "    \n",
    "    \n",
    "    # Retrieve dense results using the dense retrieval function.\n",
    "    dense_results = config[\"dense_func\"](query_dense, config[\"dense_config\"])\n",
    "    \n",
    "    if mode == \"intersection\":\n",
    "        # Use only candidates that appear in the sparse results.\n",
    "        candidate_ids = set(r[\"chunk_id\"] for r in sparse_results)\n",
    "        filtered_dense = [r for r in dense_results if r[\"chunk_id\"] in candidate_ids]\n",
    "        if not filtered_dense:\n",
    "            # If no overlap, fall back to all dense results.\n",
    "            filtered_dense = dense_results\n",
    "    elif mode == \"union\":\n",
    "        # Use the union of candidate IDs from sparse and dense retrieval.\n",
    "        candidate_ids = set(r[\"chunk_id\"] for r in sparse_results).union(\n",
    "                        set(r[\"chunk_id\"] for r in dense_results))\n",
    "        # Build a dictionary for dense results (using dense score), with default 0 if not present.\n",
    "        dense_dict = {r[\"chunk_id\"]: r for r in dense_results}\n",
    "        filtered_dense = []\n",
    "        for cid in candidate_ids:\n",
    "            if cid in dense_dict:\n",
    "                filtered_dense.append(dense_dict[cid])\n",
    "            else:\n",
    "                # If candidate from sparse isn't in dense, create a dummy entry with 0 score.\n",
    "                filtered_dense.append({\"chunk_id\": cid, \"score\": 0.0})\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Choose 'intersection' or 'union'.\")\n",
    "    \n",
    "    # Sort the filtered dense results by their dense score (highest first).\n",
    "    sorted_dense = sorted(filtered_dense, key=lambda x: x[\"score\"], reverse=True)\n",
    "    final_results = sorted_dense[:final_k]\n",
    "    return final_results\n",
    "def hybrid(query, config):\n",
    "    \"\"\"\n",
    "    Hybrid retrieval: first retrieve candidates with one method, then re-rank with the other.\n",
    "    \n",
    "    The order is determined by config[\"order\"]:\n",
    "      - \"sparse_dense\" (default): Use query[0] (or query if not a list) for sparse retrieval,\n",
    "                                   then query[1] (or query) for dense retrieval.\n",
    "      - \"dense_sparse\": Use query[0] for dense retrieval,\n",
    "                        then query[1] for sparse retrieval.\n",
    "    \n",
    "    The candidate sets are combined (using the \"mode\": \"intersection\" or \"union\")\n",
    "    and then sorted by the score of the re-ranking model.\n",
    "    \n",
    "    Parameters:\n",
    "      - query (str or list): If a list of at least two elements, the two parts will be used\n",
    "                             in the order specified by config[\"order\"]. Otherwise, the same query is used.\n",
    "      - config (dict): Must contain:\n",
    "          * \"order\": either \"sparse_dense\" (default) or \"dense_sparse\"\n",
    "          * \"sparse_func\": sparse retrieval function (e.g., tfidf_retrieval or bm25_retrieval)\n",
    "          * \"sparse_config\": configuration for the sparse method.\n",
    "          * \"dense_func\": dense retrieval function (e.g., dense_retrieval_subqueries)\n",
    "          * \"dense_config\": configuration for the dense method.\n",
    "          * \"intermediate_k\": candidate set size (default: 30)\n",
    "          * \"final_k\": final result count (default: 5)\n",
    "          * \"mode\": \"intersection\" (default) or \"union\"\n",
    "    \n",
    "    Returns:\n",
    "      A list of final results (dictionaries) from the re-ranking step.\n",
    "    \"\"\"\n",
    "    order = config.get(\"order\", \"sparse_dense\")\n",
    "    intermediate_k = config.get(\"intermediate_k\", 30)\n",
    "    final_k = config.get(\"final_k\", 5)\n",
    "    mode = config.get(\"mode\", \"intersection\")\n",
    "    \n",
    "    # Decide which query part to use for each retrieval step.\n",
    "    if isinstance(query, list) and len(query) >= 2:\n",
    "        query_sparse = query[0]\n",
    "        query_dense = query[1]\n",
    "    else:\n",
    "        print(\"Query should be a list of two queries: [sparse_query, dense_query].\")\n",
    "\n",
    "\n",
    "    if order == \"sparse_dense\":\n",
    "        # Sparse retrieval first.\n",
    "        sparse_config = config[\"sparse_config\"].copy()\n",
    "        sparse_config[\"top_k\"] = intermediate_k\n",
    "        sparse_results = config[\"sparse_func\"](query_sparse, sparse_config)\n",
    "        \n",
    "        # Dense retrieval.\n",
    "        dense_results = config[\"dense_func\"](query_dense, config[\"dense_config\"])\n",
    "        \n",
    "        # Combine: here we choose to filter dense results by the candidate set from sparse.\n",
    "        candidate_ids = set(r[\"chunk_id\"] for r in sparse_results)\n",
    "        filtered_dense = [r for r in dense_results if r[\"chunk_id\"] in candidate_ids]\n",
    "        if not filtered_dense:\n",
    "            filtered_dense = dense_results\n",
    "        # Sort by dense score.\n",
    "        sorted_results = sorted(filtered_dense, key=lambda x: x[\"score\"], reverse=True)\n",
    "    \n",
    "    elif order == \"dense_sparse\":\n",
    "        # Dense retrieval first.\n",
    "        dense_results = config[\"dense_func\"](query_dense, config[\"dense_config\"])\n",
    "        # Sparse retrieval.\n",
    "        sparse_config = config[\"sparse_config\"].copy()\n",
    "        sparse_config[\"top_k\"] = intermediate_k\n",
    "        sparse_results = config[\"sparse_func\"](query_sparse, sparse_config)\n",
    "        # Combine: filter sparse results by dense candidate set.\n",
    "        candidate_ids = set(r[\"chunk_id\"] for r in dense_results)\n",
    "        filtered_sparse = [r for r in sparse_results if r[\"chunk_id\"] in candidate_ids]\n",
    "        if not filtered_sparse:\n",
    "            filtered_sparse = sparse_results\n",
    "        # Sort by sparse score.\n",
    "        sorted_results = sorted(filtered_sparse, key=lambda x: x[\"score\"], reverse=True)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid order specified.\")\n",
    "    \n",
    "    return sorted_results[:final_k]\n",
    "\n",
    "#########################################\n",
    "# Dataset Configuration\n",
    "#########################################\n",
    "\n",
    "# Global corpus (for all retrieval methods that use it).\n",
    "def load_corpus(corpus_file):\n",
    "    with open(corpus_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    passages = [entry[\"passage\"] for entry in data if \"passage\" in entry]\n",
    "    chunk_ids = [entry[\"chunk_id\"] for entry in data if \"chunk_id\" in entry]\n",
    "    print(f\"Loaded {len(passages)} corpus passages\")\n",
    "    return passages, chunk_ids\n",
    "\n",
    "# Paths for the corpus and QA sets.\n",
    "CORPUS_FILE = \"./data/chunked_text_all_together_cleaned.json\"\n",
    "QA_PATH = \"./data/QA_set\"\n",
    "QA_EMBEDDED_PATH = \"./data/QA_set_embedded\"\n",
    "\n",
    "# Load the corpus and build common indexes.\n",
    "passages, chunk_ids = load_corpus(CORPUS_FILE)\n",
    "\n",
    "# Build TF-IDF index for the corpus.\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "doc_matrix = tfidf_vectorizer.fit_transform(passages)\n",
    "\n",
    "# Build BM25 index for the corpus.\n",
    "tokenized_passages = [word_tokenize(p.lower()) for p in passages]\n",
    "bm25 = BM25Okapi(tokenized_passages)\n",
    "\n",
    "# Load global dense corpus index (FAISS).\n",
    "corpus_dense_index = faiss.read_index(\"./hp_all_bge.index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'easy_single': loaded 253 ground truth examples.\n",
      "Evaluated tfidf on easy_single: {'recall@5': 0.08389261744966443, 'recall@10': 0.12416107382550336, 'precision@5': 0.004940711462450593, 'precision@10': 0.007312252964426878, 'mrr': 0.0647274655644802, 'ndcg@5': 0.05913122106512458, 'ndcg@10': 0.07361285003547607}\n",
      "Evaluated bm25 on easy_single: {'recall@5': 0.08389261744966443, 'recall@10': 0.15436241610738255, 'precision@5': 0.004940711462450593, 'precision@10': 0.00909090909090909, 'mrr': 0.0636334769291915, 'ndcg@5': 0.05909196015880151, 'ndcg@10': 0.08244786017469655}\n",
      "Evaluated dense on easy_single: {'recall@5': 0.15100671140939598, 'recall@10': 0.21140939597315436, 'precision@5': 0.008893280632411068, 'precision@10': 0.012450592885375493, 'mrr': 0.11776788145074586, 'ndcg@5': 0.11317977067850814, 'ndcg@10': 0.13352461988268502}\n",
      "Evaluated tfidf_dense on easy_single: {'recall@5': 0.020134228187919462, 'recall@10': 0.1040268456375839, 'precision@5': 0.0019348597226701064, 'precision@10': 0.00999677523379555, 'mrr': 0.02613959116164845, 'ndcg@5': 0.008925712028827342, 'ndcg@10': 0.03772333331189638}\n",
      "Evaluated bm25_dense on easy_single: {'recall@5': 0.026845637583892617, 'recall@10': 0.12080536912751678, 'precision@5': 0.003073376872839032, 'precision@10': 0.013830195927775643, 'mrr': 0.031001718385466337, 'ndcg@5': 0.014699768137381431, 'ndcg@10': 0.04662101401331706}\n",
      "Evaluated dense_tfidf on easy_single: {'recall@5': 0.12751677852348994, 'recall@10': 0.174496644295302, 'precision@5': 0.012254111576910674, 'precision@10': 0.01676878426314092, 'mrr': 0.09328174570269428, 'ndcg@5': 0.0919112108736717, 'ndcg@10': 0.10824191698889046}\n",
      "Evaluated dense_bm25 on easy_single: {'recall@5': 0.12416107382550336, 'recall@10': 0.16778523489932887, 'precision@5': 0.014214368036880523, 'precision@10': 0.01920860545524395, 'mrr': 0.08201310108424732, 'ndcg@5': 0.08376803582226985, 'ndcg@10': 0.09928893232990277}\n",
      "Dataset 'medium_single': loaded 91 ground truth examples.\n",
      "Evaluated tfidf on medium_single: {'recall@5': 0.136, 'recall@10': 0.184, 'precision@5': 0.00934065934065934, 'precision@10': 0.012637362637362638, 'mrr': 0.1221554696829422, 'ndcg@5': 0.1106424051223992, 'ndcg@10': 0.12665075284931043}\n",
      "Evaluated bm25 on medium_single: {'recall@5': 0.12, 'recall@10': 0.16, 'precision@5': 0.008241758241758242, 'precision@10': 0.01098901098901099, 'mrr': 0.11703980743888205, 'ndcg@5': 0.11453206515215979, 'ndcg@10': 0.1288959184344231}\n",
      "Evaluated dense on medium_single: {'recall@5': 0.152, 'recall@10': 0.232, 'precision@5': 0.00347985347985348, 'precision@10': 0.005311355311355312, 'mrr': 0.15061068215672854, 'ndcg@5': 0.12090768227829109, 'ndcg@10': 0.15686128316103606}\n",
      "Evaluated tfidf_dense on medium_single: {'recall@5': 0.032, 'recall@10': 0.056, 'precision@5': 0.0022271714922048997, 'precision@10': 0.0038975501113585748, 'mrr': 0.024042809228482686, 'ndcg@5': 0.01814198823963882, 'ndcg@10': 0.03195255404896339}\n",
      "Evaluated bm25_dense on medium_single: {'recall@5': 0.032, 'recall@10': 0.088, 'precision@5': 0.0022484541877459247, 'precision@10': 0.006183249016301293, 'mrr': 0.03224274086256532, 'ndcg@5': 0.02141163866900431, 'ndcg@10': 0.049699056557483086}\n",
      "Evaluated dense_tfidf on medium_single: {'recall@5': 0.168, 'recall@10': 0.208, 'precision@5': 0.012396694214876033, 'precision@10': 0.015348288075560802, 'mrr': 0.1693827584826292, 'ndcg@5': 0.14817099073607748, 'ndcg@10': 0.1626772842070604}\n",
      "Evaluated dense_bm25 on medium_single: {'recall@5': 0.176, 'recall@10': 0.216, 'precision@5': 0.013341419041843541, 'precision@10': 0.01637355973317162, 'mrr': 0.14586412653639544, 'ndcg@5': 0.14469677193514452, 'ndcg@10': 0.160122686734721}\n",
      "Dataset 'medium_multi': loaded 35 ground truth examples.\n",
      "Evaluated tfidf on medium_multi: {'recall@5': 0.006802721088435374, 'recall@10': 0.006802721088435374, 'precision@5': 0.0014285714285714286, 'precision@10': 0.0014285714285714286, 'mrr': 0.03211600429645542, 'ndcg@5': 0.017518491221870238, 'ndcg@10': 0.017518491221870238}\n",
      "Evaluated bm25 on medium_multi: {'recall@5': 0.027210884353741496, 'recall@10': 0.04081632653061224, 'precision@5': 0.005714285714285714, 'precision@10': 0.008571428571428572, 'mrr': 0.06294610151753008, 'ndcg@5': 0.03288943101954012, 'ndcg@10': 0.03629333292455425}\n",
      "Evaluated dense on medium_multi: {'recall@5': 0.034013605442176874, 'recall@10': 0.04081632653061224, 'precision@5': 0.002380952380952381, 'precision@10': 0.002857142857142857, 'mrr': 0.0965951978039496, 'ndcg@5': 0.0492483564001426, 'ndcg@10': 0.051384051909536134}\n",
      "Evaluated tfidf_dense on medium_multi: {'recall@5': 0.013605442176870748, 'recall@10': 0.02040816326530612, 'precision@5': 0.002886002886002886, 'precision@10': 0.004329004329004329, 'mrr': 0.02600732600732601, 'ndcg@5': 0.010950458931771505, 'ndcg@10': 0.012937067995381179}\n",
      "Evaluated bm25_dense on medium_multi: {'recall@5': 0.0, 'recall@10': 0.013605442176870748, 'precision@5': 0.0, 'precision@10': 0.0029154518950437317, 'mrr': 0.01955190173235286, 'ndcg@5': 0.0, 'ndcg@10': 0.008480163022766843}\n",
      "Evaluated dense_tfidf on medium_multi: {'recall@5': 0.02040816326530612, 'recall@10': 0.04081632653061224, 'precision@5': 0.004405286343612335, 'precision@10': 0.00881057268722467, 'mrr': 0.08558467847941531, 'ndcg@5': 0.03475358630319044, 'ndcg@10': 0.045196312130972825}\n",
      "Evaluated dense_bm25 on medium_multi: {'recall@5': 0.013605442176870748, 'recall@10': 0.04081632653061224, 'precision@5': 0.0029985007496251873, 'precision@10': 0.008995502248875561, 'mrr': 0.06333333333333332, 'ndcg@5': 0.023632384499999597, 'ndcg@10': 0.04227752731467377}\n",
      "Dataset 'hard_single': loaded 11 ground truth examples.\n",
      "Evaluated tfidf on hard_single: {'recall@5': 0.05555555555555555, 'recall@10': 0.1111111111111111, 'precision@5': 0.004545454545454545, 'precision@10': 0.00909090909090909, 'mrr': 0.045454545454545456, 'ndcg@5': 0.02787032694388447, 'ndcg@10': 0.06025279849915921}\n",
      "Evaluated bm25 on hard_single: {'recall@5': 0.1111111111111111, 'recall@10': 0.1111111111111111, 'precision@5': 0.00909090909090909, 'precision@10': 0.00909090909090909, 'mrr': 0.045454545454545456, 'ndcg@5': 0.06315860733145308, 'ndcg@10': 0.06315860733145308}\n",
      "Evaluated dense on hard_single: {'recall@5': 0.1111111111111111, 'recall@10': 0.2222222222222222, 'precision@5': 0.0030303030303030303, 'precision@10': 0.006060606060606061, 'mrr': 0.2078691045796309, 'ndcg@5': 0.08532340473141026, 'ndcg@10': 0.11565663462155874}\n",
      "Evaluated tfidf_dense on hard_single: {'recall@5': 0.1111111111111111, 'recall@10': 0.16666666666666666, 'precision@5': 0.01015228426395939, 'precision@10': 0.015228426395939087, 'mrr': 0.07644628099173555, 'ndcg@5': 0.06315860733145308, 'ndcg@10': 0.09052497057363319}\n",
      "Evaluated bm25_dense on hard_single: {'recall@5': 0.1111111111111111, 'recall@10': 0.2777777777777778, 'precision@5': 0.011834319526627219, 'precision@10': 0.029585798816568046, 'mrr': 0.08268398268398268, 'ndcg@5': 0.06315860733145308, 'ndcg@10': 0.15576032528518707}\n",
      "Evaluated dense_tfidf on hard_single: {'recall@5': 0.16666666666666666, 'recall@10': 0.2777777777777778, 'precision@5': 0.017045454545454544, 'precision@10': 0.028409090909090908, 'mrr': 0.08939393939393939, 'ndcg@5': 0.08141215910161986, 'ndcg@10': 0.13396940025032675}\n",
      "Evaluated dense_bm25 on hard_single: {'recall@5': 0.16666666666666666, 'recall@10': 0.2777777777777778, 'precision@5': 0.01910828025477707, 'precision@10': 0.03184713375796178, 'mrr': 0.13560606060606062, 'ndcg@5': 0.10902948666757743, 'ndcg@10': 0.17009058338519115}\n",
      "Dataset 'hard_multi': loaded 12 ground truth examples.\n",
      "Evaluated tfidf on hard_multi: {'recall@5': 0.08333333333333333, 'recall@10': 0.08333333333333333, 'precision@5': 0.008333333333333333, 'precision@10': 0.008333333333333333, 'mrr': 0.05555555555555555, 'ndcg@5': 0.05109559939712153, 'ndcg@10': 0.05109559939712153}\n",
      "Evaluated bm25 on hard_multi: {'recall@5': 0.041666666666666664, 'recall@10': 0.041666666666666664, 'precision@5': 0.004166666666666667, 'precision@10': 0.004166666666666667, 'mrr': 0.027777777777777776, 'ndcg@5': 0.025547799698560764, 'ndcg@10': 0.025547799698560764}\n",
      "Evaluated dense on hard_multi: {'recall@5': 0.041666666666666664, 'recall@10': 0.041666666666666664, 'precision@5': 0.001388888888888889, 'precision@10': 0.001388888888888889, 'mrr': 0.08712121212121211, 'ndcg@5': 0.05109559939712153, 'ndcg@10': 0.05109559939712153}\n",
      "Evaluated tfidf_dense on hard_multi: {'recall@5': 0.0, 'recall@10': 0.041666666666666664, 'precision@5': 0.0, 'precision@10': 0.004201680672268907, 'mrr': 0.009259259259259259, 'ndcg@5': 0.0, 'ndcg@10': 0.015381308064964015}\n",
      "Evaluated bm25_dense on hard_multi: {'recall@5': 0.0, 'recall@10': 0.0, 'precision@5': 0.0, 'precision@10': 0.0, 'mrr': 0.0, 'ndcg@5': 0.0, 'ndcg@10': 0.0}\n",
      "Evaluated dense_tfidf on hard_multi: {'recall@5': 0.041666666666666664, 'recall@10': 0.08333333333333333, 'precision@5': 0.004329004329004329, 'precision@10': 0.008658008658008658, 'mrr': 0.049999999999999996, 'ndcg@5': 0.0322377339362118, 'ndcg@10': 0.047007674501549114}\n",
      "Evaluated dense_bm25 on hard_multi: {'recall@5': 0.0, 'recall@10': 0.041666666666666664, 'precision@5': 0.0, 'precision@10': 0.004672897196261682, 'mrr': 0.009259259259259259, 'ndcg@5': 0.0, 'ndcg@10': 0.015381308064964015}\n",
      "Final Results:\n",
      "[{'data_set': 'easy_single', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.08389261744966443, 'recall@10': 0.12416107382550336, 'precision@5': 0.004940711462450593, 'precision@10': 0.007312252964426878, 'mrr': 0.0647274655644802, 'ndcg@5': 0.05913122106512458, 'ndcg@10': 0.07361285003547607}}, {'data_set': 'easy_single', 'retrieval': 'bm25', 'performance': {'recall@5': 0.08389261744966443, 'recall@10': 0.15436241610738255, 'precision@5': 0.004940711462450593, 'precision@10': 0.00909090909090909, 'mrr': 0.0636334769291915, 'ndcg@5': 0.05909196015880151, 'ndcg@10': 0.08244786017469655}}, {'data_set': 'easy_single', 'retrieval': 'dense', 'performance': {'recall@5': 0.15100671140939598, 'recall@10': 0.21140939597315436, 'precision@5': 0.008893280632411068, 'precision@10': 0.012450592885375493, 'mrr': 0.11776788145074586, 'ndcg@5': 0.11317977067850814, 'ndcg@10': 0.13352461988268502}}, {'data_set': 'medium_single', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.136, 'recall@10': 0.184, 'precision@5': 0.00934065934065934, 'precision@10': 0.012637362637362638, 'mrr': 0.1221554696829422, 'ndcg@5': 0.1106424051223992, 'ndcg@10': 0.12665075284931043}}, {'data_set': 'medium_single', 'retrieval': 'bm25', 'performance': {'recall@5': 0.12, 'recall@10': 0.16, 'precision@5': 0.008241758241758242, 'precision@10': 0.01098901098901099, 'mrr': 0.11703980743888205, 'ndcg@5': 0.11453206515215979, 'ndcg@10': 0.1288959184344231}}, {'data_set': 'medium_single', 'retrieval': 'dense', 'performance': {'recall@5': 0.152, 'recall@10': 0.232, 'precision@5': 0.00347985347985348, 'precision@10': 0.005311355311355312, 'mrr': 0.15061068215672854, 'ndcg@5': 0.12090768227829109, 'ndcg@10': 0.15686128316103606}}, {'data_set': 'medium_multi', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.006802721088435374, 'recall@10': 0.006802721088435374, 'precision@5': 0.0014285714285714286, 'precision@10': 0.0014285714285714286, 'mrr': 0.03211600429645542, 'ndcg@5': 0.017518491221870238, 'ndcg@10': 0.017518491221870238}}, {'data_set': 'medium_multi', 'retrieval': 'bm25', 'performance': {'recall@5': 0.027210884353741496, 'recall@10': 0.04081632653061224, 'precision@5': 0.005714285714285714, 'precision@10': 0.008571428571428572, 'mrr': 0.06294610151753008, 'ndcg@5': 0.03288943101954012, 'ndcg@10': 0.03629333292455425}}, {'data_set': 'medium_multi', 'retrieval': 'dense', 'performance': {'recall@5': 0.034013605442176874, 'recall@10': 0.04081632653061224, 'precision@5': 0.002380952380952381, 'precision@10': 0.002857142857142857, 'mrr': 0.0965951978039496, 'ndcg@5': 0.0492483564001426, 'ndcg@10': 0.051384051909536134}}, {'data_set': 'hard_single', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.05555555555555555, 'recall@10': 0.1111111111111111, 'precision@5': 0.004545454545454545, 'precision@10': 0.00909090909090909, 'mrr': 0.045454545454545456, 'ndcg@5': 0.02787032694388447, 'ndcg@10': 0.06025279849915921}}, {'data_set': 'hard_single', 'retrieval': 'bm25', 'performance': {'recall@5': 0.1111111111111111, 'recall@10': 0.1111111111111111, 'precision@5': 0.00909090909090909, 'precision@10': 0.00909090909090909, 'mrr': 0.045454545454545456, 'ndcg@5': 0.06315860733145308, 'ndcg@10': 0.06315860733145308}}, {'data_set': 'hard_single', 'retrieval': 'dense', 'performance': {'recall@5': 0.1111111111111111, 'recall@10': 0.2222222222222222, 'precision@5': 0.0030303030303030303, 'precision@10': 0.006060606060606061, 'mrr': 0.2078691045796309, 'ndcg@5': 0.08532340473141026, 'ndcg@10': 0.11565663462155874}}, {'data_set': 'hard_multi', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.08333333333333333, 'recall@10': 0.08333333333333333, 'precision@5': 0.008333333333333333, 'precision@10': 0.008333333333333333, 'mrr': 0.05555555555555555, 'ndcg@5': 0.05109559939712153, 'ndcg@10': 0.05109559939712153}}, {'data_set': 'hard_multi', 'retrieval': 'bm25', 'performance': {'recall@5': 0.041666666666666664, 'recall@10': 0.041666666666666664, 'precision@5': 0.004166666666666667, 'precision@10': 0.004166666666666667, 'mrr': 0.027777777777777776, 'ndcg@5': 0.025547799698560764, 'ndcg@10': 0.025547799698560764}}, {'data_set': 'hard_multi', 'retrieval': 'dense', 'performance': {'recall@5': 0.041666666666666664, 'recall@10': 0.041666666666666664, 'precision@5': 0.001388888888888889, 'precision@10': 0.001388888888888889, 'mrr': 0.08712121212121211, 'ndcg@5': 0.05109559939712153, 'ndcg@10': 0.05109559939712153}}, {'data_set': 'easy_single', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.08389261744966443, 'recall@10': 0.12416107382550336, 'precision@5': 0.004940711462450593, 'precision@10': 0.007312252964426878, 'mrr': 0.0647274655644802, 'ndcg@5': 0.05913122106512458, 'ndcg@10': 0.07361285003547607}}, {'data_set': 'easy_single', 'retrieval': 'bm25', 'performance': {'recall@5': 0.08389261744966443, 'recall@10': 0.15436241610738255, 'precision@5': 0.004940711462450593, 'precision@10': 0.00909090909090909, 'mrr': 0.0636334769291915, 'ndcg@5': 0.05909196015880151, 'ndcg@10': 0.08244786017469655}}, {'data_set': 'easy_single', 'retrieval': 'dense', 'performance': {'recall@5': 0.15100671140939598, 'recall@10': 0.21140939597315436, 'precision@5': 0.008893280632411068, 'precision@10': 0.012450592885375493, 'mrr': 0.11776788145074586, 'ndcg@5': 0.11317977067850814, 'ndcg@10': 0.13352461988268502}}, {'data_set': 'easy_single', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.020134228187919462, 'recall@10': 0.1040268456375839, 'precision@5': 0.0019348597226701064, 'precision@10': 0.00999677523379555, 'mrr': 0.02613959116164845, 'ndcg@5': 0.008925712028827342, 'ndcg@10': 0.03772333331189638}}, {'data_set': 'easy_single', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.026845637583892617, 'recall@10': 0.12080536912751678, 'precision@5': 0.003073376872839032, 'precision@10': 0.013830195927775643, 'mrr': 0.031001718385466337, 'ndcg@5': 0.014699768137381431, 'ndcg@10': 0.04662101401331706}}, {'data_set': 'easy_single', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.12751677852348994, 'recall@10': 0.174496644295302, 'precision@5': 0.012254111576910674, 'precision@10': 0.01676878426314092, 'mrr': 0.09328174570269428, 'ndcg@5': 0.0919112108736717, 'ndcg@10': 0.10824191698889046}}, {'data_set': 'easy_single', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.12416107382550336, 'recall@10': 0.16778523489932887, 'precision@5': 0.014214368036880523, 'precision@10': 0.01920860545524395, 'mrr': 0.08201310108424732, 'ndcg@5': 0.08376803582226985, 'ndcg@10': 0.09928893232990277}}, {'data_set': 'medium_single', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.136, 'recall@10': 0.184, 'precision@5': 0.00934065934065934, 'precision@10': 0.012637362637362638, 'mrr': 0.1221554696829422, 'ndcg@5': 0.1106424051223992, 'ndcg@10': 0.12665075284931043}}, {'data_set': 'medium_single', 'retrieval': 'bm25', 'performance': {'recall@5': 0.12, 'recall@10': 0.16, 'precision@5': 0.008241758241758242, 'precision@10': 0.01098901098901099, 'mrr': 0.11703980743888205, 'ndcg@5': 0.11453206515215979, 'ndcg@10': 0.1288959184344231}}, {'data_set': 'medium_single', 'retrieval': 'dense', 'performance': {'recall@5': 0.152, 'recall@10': 0.232, 'precision@5': 0.00347985347985348, 'precision@10': 0.005311355311355312, 'mrr': 0.15061068215672854, 'ndcg@5': 0.12090768227829109, 'ndcg@10': 0.15686128316103606}}, {'data_set': 'medium_single', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.032, 'recall@10': 0.056, 'precision@5': 0.0022271714922048997, 'precision@10': 0.0038975501113585748, 'mrr': 0.024042809228482686, 'ndcg@5': 0.01814198823963882, 'ndcg@10': 0.03195255404896339}}, {'data_set': 'medium_single', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.032, 'recall@10': 0.088, 'precision@5': 0.0022484541877459247, 'precision@10': 0.006183249016301293, 'mrr': 0.03224274086256532, 'ndcg@5': 0.02141163866900431, 'ndcg@10': 0.049699056557483086}}, {'data_set': 'medium_single', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.168, 'recall@10': 0.208, 'precision@5': 0.012396694214876033, 'precision@10': 0.015348288075560802, 'mrr': 0.1693827584826292, 'ndcg@5': 0.14817099073607748, 'ndcg@10': 0.1626772842070604}}, {'data_set': 'medium_single', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.176, 'recall@10': 0.216, 'precision@5': 0.013341419041843541, 'precision@10': 0.01637355973317162, 'mrr': 0.14586412653639544, 'ndcg@5': 0.14469677193514452, 'ndcg@10': 0.160122686734721}}, {'data_set': 'medium_multi', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.006802721088435374, 'recall@10': 0.006802721088435374, 'precision@5': 0.0014285714285714286, 'precision@10': 0.0014285714285714286, 'mrr': 0.03211600429645542, 'ndcg@5': 0.017518491221870238, 'ndcg@10': 0.017518491221870238}}, {'data_set': 'medium_multi', 'retrieval': 'bm25', 'performance': {'recall@5': 0.027210884353741496, 'recall@10': 0.04081632653061224, 'precision@5': 0.005714285714285714, 'precision@10': 0.008571428571428572, 'mrr': 0.06294610151753008, 'ndcg@5': 0.03288943101954012, 'ndcg@10': 0.03629333292455425}}, {'data_set': 'medium_multi', 'retrieval': 'dense', 'performance': {'recall@5': 0.034013605442176874, 'recall@10': 0.04081632653061224, 'precision@5': 0.002380952380952381, 'precision@10': 0.002857142857142857, 'mrr': 0.0965951978039496, 'ndcg@5': 0.0492483564001426, 'ndcg@10': 0.051384051909536134}}, {'data_set': 'medium_multi', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.013605442176870748, 'recall@10': 0.02040816326530612, 'precision@5': 0.002886002886002886, 'precision@10': 0.004329004329004329, 'mrr': 0.02600732600732601, 'ndcg@5': 0.010950458931771505, 'ndcg@10': 0.012937067995381179}}, {'data_set': 'medium_multi', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.0, 'recall@10': 0.013605442176870748, 'precision@5': 0.0, 'precision@10': 0.0029154518950437317, 'mrr': 0.01955190173235286, 'ndcg@5': 0.0, 'ndcg@10': 0.008480163022766843}}, {'data_set': 'medium_multi', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.02040816326530612, 'recall@10': 0.04081632653061224, 'precision@5': 0.004405286343612335, 'precision@10': 0.00881057268722467, 'mrr': 0.08558467847941531, 'ndcg@5': 0.03475358630319044, 'ndcg@10': 0.045196312130972825}}, {'data_set': 'medium_multi', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.013605442176870748, 'recall@10': 0.04081632653061224, 'precision@5': 0.0029985007496251873, 'precision@10': 0.008995502248875561, 'mrr': 0.06333333333333332, 'ndcg@5': 0.023632384499999597, 'ndcg@10': 0.04227752731467377}}, {'data_set': 'hard_single', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.05555555555555555, 'recall@10': 0.1111111111111111, 'precision@5': 0.004545454545454545, 'precision@10': 0.00909090909090909, 'mrr': 0.045454545454545456, 'ndcg@5': 0.02787032694388447, 'ndcg@10': 0.06025279849915921}}, {'data_set': 'hard_single', 'retrieval': 'bm25', 'performance': {'recall@5': 0.1111111111111111, 'recall@10': 0.1111111111111111, 'precision@5': 0.00909090909090909, 'precision@10': 0.00909090909090909, 'mrr': 0.045454545454545456, 'ndcg@5': 0.06315860733145308, 'ndcg@10': 0.06315860733145308}}, {'data_set': 'hard_single', 'retrieval': 'dense', 'performance': {'recall@5': 0.1111111111111111, 'recall@10': 0.2222222222222222, 'precision@5': 0.0030303030303030303, 'precision@10': 0.006060606060606061, 'mrr': 0.2078691045796309, 'ndcg@5': 0.08532340473141026, 'ndcg@10': 0.11565663462155874}}, {'data_set': 'hard_single', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.1111111111111111, 'recall@10': 0.16666666666666666, 'precision@5': 0.01015228426395939, 'precision@10': 0.015228426395939087, 'mrr': 0.07644628099173555, 'ndcg@5': 0.06315860733145308, 'ndcg@10': 0.09052497057363319}}, {'data_set': 'hard_single', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.1111111111111111, 'recall@10': 0.2777777777777778, 'precision@5': 0.011834319526627219, 'precision@10': 0.029585798816568046, 'mrr': 0.08268398268398268, 'ndcg@5': 0.06315860733145308, 'ndcg@10': 0.15576032528518707}}, {'data_set': 'hard_single', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.16666666666666666, 'recall@10': 0.2777777777777778, 'precision@5': 0.017045454545454544, 'precision@10': 0.028409090909090908, 'mrr': 0.08939393939393939, 'ndcg@5': 0.08141215910161986, 'ndcg@10': 0.13396940025032675}}, {'data_set': 'hard_single', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.16666666666666666, 'recall@10': 0.2777777777777778, 'precision@5': 0.01910828025477707, 'precision@10': 0.03184713375796178, 'mrr': 0.13560606060606062, 'ndcg@5': 0.10902948666757743, 'ndcg@10': 0.17009058338519115}}, {'data_set': 'hard_multi', 'retrieval': 'tfidf', 'performance': {'recall@5': 0.08333333333333333, 'recall@10': 0.08333333333333333, 'precision@5': 0.008333333333333333, 'precision@10': 0.008333333333333333, 'mrr': 0.05555555555555555, 'ndcg@5': 0.05109559939712153, 'ndcg@10': 0.05109559939712153}}, {'data_set': 'hard_multi', 'retrieval': 'bm25', 'performance': {'recall@5': 0.041666666666666664, 'recall@10': 0.041666666666666664, 'precision@5': 0.004166666666666667, 'precision@10': 0.004166666666666667, 'mrr': 0.027777777777777776, 'ndcg@5': 0.025547799698560764, 'ndcg@10': 0.025547799698560764}}, {'data_set': 'hard_multi', 'retrieval': 'dense', 'performance': {'recall@5': 0.041666666666666664, 'recall@10': 0.041666666666666664, 'precision@5': 0.001388888888888889, 'precision@10': 0.001388888888888889, 'mrr': 0.08712121212121211, 'ndcg@5': 0.05109559939712153, 'ndcg@10': 0.05109559939712153}}, {'data_set': 'hard_multi', 'retrieval': 'tfidf_dense', 'performance': {'recall@5': 0.0, 'recall@10': 0.041666666666666664, 'precision@5': 0.0, 'precision@10': 0.004201680672268907, 'mrr': 0.009259259259259259, 'ndcg@5': 0.0, 'ndcg@10': 0.015381308064964015}}, {'data_set': 'hard_multi', 'retrieval': 'bm25_dense', 'performance': {'recall@5': 0.0, 'recall@10': 0.0, 'precision@5': 0.0, 'precision@10': 0.0, 'mrr': 0.0, 'ndcg@5': 0.0, 'ndcg@10': 0.0}}, {'data_set': 'hard_multi', 'retrieval': 'dense_tfidf', 'performance': {'recall@5': 0.041666666666666664, 'recall@10': 0.08333333333333333, 'precision@5': 0.004329004329004329, 'precision@10': 0.008658008658008658, 'mrr': 0.049999999999999996, 'ndcg@5': 0.0322377339362118, 'ndcg@10': 0.047007674501549114}}, {'data_set': 'hard_multi', 'retrieval': 'dense_bm25', 'performance': {'recall@5': 0.0, 'recall@10': 0.041666666666666664, 'precision@5': 0.0, 'precision@10': 0.004672897196261682, 'mrr': 0.009259259259259259, 'ndcg@5': 0.0, 'ndcg@10': 0.015381308064964015}}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define dataset configurations.\n",
    "# For each dataset, specify:\n",
    "#  - \"name\": a short name,\n",
    "#  - \"gt_path\": path to the ground truth QA file,\n",
    "#  - For dense retrieval: \"subqueries\" (list) and \"subquery_index\" (FAISS index file path).\n",
    "datasets = [\n",
    "    {\n",
    "        \"name\": \"easy_single\",\n",
    "        \"gt_path\": os.path.join(QA_PATH, \"easy_single_labeled.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join(QA_PATH, \"easy_single_labeled.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"bge_easy_single_labeled.index\"))\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"medium_single\",\n",
    "        \"gt_path\": os.path.join(QA_PATH, \"medium_single_labeled.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join(QA_PATH, \"medium_single_labeled.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"bge_medium_single_labeled.index\"))\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"medium_multi\",\n",
    "        \"gt_path\": os.path.join(QA_PATH, \"medium_multi_labeled.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join(QA_PATH, \"medium_multi_labeled.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"bge_medium_multi_labeled.index\"))\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"hard_single\",\n",
    "        \"gt_path\": os.path.join(QA_PATH, \"hard_single_labeled.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join(QA_PATH, \"hard_single_labeled.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"bge_hard_single_labeled.index\"))\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"hard_multi\",\n",
    "        \"gt_path\": os.path.join(QA_PATH, \"hard_multi_labeled.json\"),\n",
    "        \"dense\": {\n",
    "            \"subqueries\": retrieve_all_subqueries(os.path.join(QA_PATH, \"hard_multi_labeled.json\")),\n",
    "            \"subquery_index\": faiss.read_index(os.path.join(QA_EMBEDDED_PATH, \"bge_hard_multi_labeled.index\"))\n",
    "        }\n",
    "    }\n",
    "]\n",
    "# A helper function to load subqueries from a ground truth file.\n",
    "def retrieve_all_subqueries(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        qa_data = json.load(f)\n",
    "    subqueries = []\n",
    "    for item in qa_data:\n",
    "        subqueries.extend(item[\"sub_questions\"])\n",
    "    return subqueries\n",
    "\n",
    "#########################################\n",
    "# Retrieval Methods Configuration\n",
    "#########################################\n",
    "\n",
    "# Create a dictionary mapping retrieval method names to their functions.\n",
    "retrieval_methods = {\n",
    "    \"tfidf\": tfidf_retrieval,\n",
    "    \"bm25\": bm25_retrieval,\n",
    "    \"dense\": dense_retrieval_subqueries,\n",
    "    \"tfidf_dense\": hybrid,\n",
    "    \"bm25_dense\": hybrid,\n",
    "    \"dense_tfidf\": hybrid,\n",
    "    \"dense_bm25\": hybrid,\n",
    "}\n",
    "\n",
    "# For each dataset, define a configuration for each retrieval method.\n",
    "# Here we create a dictionary keyed by retrieval method for each dataset.\n",
    "for ds in datasets:\n",
    "    ds.setdefault(\"retrieval_config\", {})\n",
    "    #TF-IDF configuration.\n",
    "    ds[\"retrieval_config\"][\"tfidf\"] = {\n",
    "        \"passages\": passages,\n",
    "        \"chunk_ids\": chunk_ids,\n",
    "        \"vectorizer\": tfidf_vectorizer,\n",
    "        \"doc_matrix\": doc_matrix,\n",
    "        \"top_k\": 20,\n",
    "        \"query_type\": \"question\"  # or \"sub_questions\" based on your data structure\n",
    "    }\n",
    "    # BM25 configuration.\n",
    "    ds[\"retrieval_config\"][\"bm25\"] = {\n",
    "        \"passages\": passages,\n",
    "        \"chunk_ids\": chunk_ids,\n",
    "        \"bm25\": bm25,\n",
    "        \"top_k\": 20,\n",
    "        \"query_type\": \"question\"  # or \"sub_questions\" based on your data structure\n",
    "    }\n",
    "    #Dense retrieval configuration.\n",
    "    ds[\"retrieval_config\"][\"dense\"] = {\n",
    "        \"passages\": passages,\n",
    "        \"chunk_ids\": chunk_ids,\n",
    "        \"all_subqueries\": ds[\"dense\"][\"subqueries\"],\n",
    "        \"subquery_index\": ds[\"dense\"][\"subquery_index\"],\n",
    "        \"faiss_index\": corpus_dense_index,\n",
    "        \"top_k\": 20,\n",
    "        \"query_type\": \"sub_questions\"  # or \"question\" based on your data structure\n",
    "    }\n",
    "        # --- Add Hybrid Configurations ---\n",
    "    # Hybrid TF-IDF + Dense configuration.\n",
    "    ds[\"retrieval_config\"][\"tfidf_dense\"] = {\n",
    "        \"sparse_func\": tfidf_retrieval,\n",
    "        \"sparse_config\": ds[\"retrieval_config\"][\"tfidf\"],\n",
    "        \"dense_func\": dense_retrieval_subqueries,\n",
    "        \"dense_config\": ds[\"retrieval_config\"][\"dense\"],\n",
    "        \"intermediate_k\": 1000,   # You can choose this value independently.\n",
    "        \"final_k\": 20,           # And choose the final number of results.\n",
    "        \"mode\": \"intersection\" , # or \"union\"\n",
    "        \"query_type\": \"combine\",  # or \"sub_questions\" based on your data structure\n",
    "        \"order\": \"sparse_dense\"  # or \"dense_sparse\"\n",
    "\n",
    "    }\n",
    "    # Hybrid BM25 + Dense configuration.\n",
    "    ds[\"retrieval_config\"][\"bm25_dense\"] = {\n",
    "        \"sparse_func\": bm25_retrieval,\n",
    "        \"sparse_config\": ds[\"retrieval_config\"][\"bm25\"],\n",
    "        \"dense_func\": dense_retrieval_subqueries,\n",
    "        \"dense_config\": ds[\"retrieval_config\"][\"dense\"],\n",
    "        \"intermediate_k\": 1000,\n",
    "        \"final_k\": 20,\n",
    "        \"mode\": \"intersection\" , # or \"union\"\n",
    "        \"query_type\": \"combine\",  # or \"sub_questions\" based on your data structure\n",
    "        \"order\": \"sparse_dense\"  # or \"dense_sparse\"\n",
    "    }\n",
    "    ds[\"retrieval_config\"][\"dense_tfidf\"] = {\n",
    "        \"sparse_func\": tfidf_retrieval,\n",
    "        \"sparse_config\": ds[\"retrieval_config\"][\"tfidf\"],\n",
    "        \"dense_func\": dense_retrieval_subqueries,\n",
    "        \"dense_config\": ds[\"retrieval_config\"][\"dense\"],\n",
    "        \"intermediate_k\": 1000,   # You can choose this value independently.\n",
    "        \"final_k\": 20,           # And choose the final number of results.\n",
    "        \"mode\": \"intersection\" , # or \"union\"\n",
    "        \"query_type\": \"combine\",  # or \"sub_questions\" based on your data structure\n",
    "        \"order\": \"dense_sparse\"  # or \"dense_sparse\"\n",
    "\n",
    "    }\n",
    "    # Hybrid BM25 + Dense configuration.\n",
    "    ds[\"retrieval_config\"][\"dense_bm25\"] = {\n",
    "        \"sparse_func\": bm25_retrieval,\n",
    "        \"sparse_config\": ds[\"retrieval_config\"][\"bm25\"],\n",
    "        \"dense_func\": dense_retrieval_subqueries,\n",
    "        \"dense_config\": ds[\"retrieval_config\"][\"dense\"],\n",
    "        \"intermediate_k\": 1000,\n",
    "        \"final_k\": 20,\n",
    "        \"mode\": \"intersection\" , # or \"union\"\n",
    "        \"query_type\": \"combine\",  # or \"sub_questions\" based on your data structure\n",
    "        \"order\": \"dense_sparse\"  # or \"dense_sparse\"\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Test Process: Evaluate Each Retrieval Method on Each Dataset\n",
    "#########################################\n",
    "# load the results\n",
    "save_path = os.path.join(QA_PATH, \"retrieval_results.json\")\n",
    "with open(save_path, \"r\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "\n",
    "for ds in datasets:\n",
    "    # Load ground truth data.\n",
    "    with open(ds[\"gt_path\"], \"r\", encoding=\"utf-8\") as f:\n",
    "        ground_truth_data = json.load(f)\n",
    "    print(f\"Dataset '{ds['name']}': loaded {len(ground_truth_data)} ground truth examples.\")\n",
    "    \n",
    "    # For each retrieval method defined in this dataset's config:\n",
    "    for method_name, method_func in retrieval_methods.items():\n",
    "        # Check if a configuration exists for this method.\n",
    "        if method_name in ds[\"retrieval_config\"]:\n",
    "            config = ds[\"retrieval_config\"][method_name]\n",
    "            predictions = []\n",
    "            references = []\n",
    "            for example in ground_truth_data:\n",
    "                query_type = config.get(\"query_type\")\n",
    "                query = [example[\"question\"], example[\"sub_questions\"]]\n",
    "                if query_type == \"sub_questions\":\n",
    "                    question = query[1]\n",
    "                elif query_type == \"question\":\n",
    "                    question = query[0]\n",
    "                else:\n",
    "                    question = query \n",
    "                ret_results = method_func(question, config)\n",
    "                # Collect predicted chunk IDs (convert to string).\n",
    "                pred_ids = [str(r[\"chunk_id\"]) for r in ret_results]\n",
    "                predictions.append(pred_ids)\n",
    "                # Ground truth: assume each reference in \"list of reference\" has a \"ref_id\".\n",
    "                gt_ids = [str(ref[\"ref_id\"]) for ref in example[\"list of reference\"]]\n",
    "                references.append(gt_ids)\n",
    "            \n",
    "            # Initialize evaluation metrics.\n",
    "            eval_collection = MetricCollection({\n",
    "                \"recall@5\": RecallAtK(k=5),\n",
    "                \"recall@10\": RecallAtK(k=10),\n",
    "                \"precision@5\": PrecisionAtK(k=5),\n",
    "                \"precision@10\": PrecisionAtK(k=10),\n",
    "                \"mrr\": MRR(),\n",
    "                \"ndcg@5\": nDCG(k=5),\n",
    "                \"ndcg@10\": nDCG(k=10)\n",
    "            })\n",
    "            eval_collection.update(predictions, references, metric_type=\"retrieval\")\n",
    "            overall_metrics = eval_collection.compute(metric_type=\"retrieval\")\n",
    "            \n",
    "            results.append({\n",
    "                \"data_set\": ds[\"name\"],\n",
    "                \"retrieval\": method_name,\n",
    "                \"performance\": overall_metrics\n",
    "            })\n",
    "            print(f\"Evaluated {method_name} on {ds['name']}: {overall_metrics}\")\n",
    "\n",
    "#########################################\n",
    "# Now 'results' contains evaluation metrics for each dataset and each retrieval method.\n",
    "#########################################\n",
    "\n",
    "# Optionally, you can now plot the results. For example, a grouped bar chart comparing methods on each dataset.\n",
    "# (You can adapt your previous plotting code using the results list.)\n",
    "print(\"Final Results:\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./data/QA_set\\retrieval_results.json\n"
     ]
    }
   ],
   "source": [
    "# save the results to a JSON file.\n",
    "save_path = os.path.join(QA_PATH, \"retrieval_results.json\")\n",
    "# Ensure the directory exists.\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "# Save the results to the specified JSON file.\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "# Print a message indicating where the results were saved.\n",
    "print(f\"Results saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
