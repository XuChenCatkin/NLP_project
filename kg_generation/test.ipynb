{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from string import Template\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "import glob\n",
    "from timeit import default_timer as timer\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")  \n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  \n",
    "api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "deployment_name = \"gpt-4\"\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "client = openai.AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_version=api_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = client.chat.completions.create(\n",
    "#     model=deployment_name, \n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"I am going to Paris, what should I see?\"},\n",
    "#     ],\n",
    "#     max_tokens=350,\n",
    "#     temperature=1.0,\n",
    "#     top_p=1.0\n",
    "# )\n",
    "# print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_uri = os.getenv(\"NEO4J_URI\")\n",
    "neo4j_user = os.getenv(\"NEO4J_USERNAME\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "gds = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call the OpenAI API\n",
    "def process_gpt(file_prompt, system_msg):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        max_tokens=350,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": file_prompt},\n",
    "        ],\n",
    "    )\n",
    "    nlp_results = completion.choices[0].message.content\n",
    "    sleep(8)\n",
    "    return nlp_results\n",
    "\n",
    "\n",
    "# Function to take folder of files and a prompt template, and return a json-object of all the entities and relationships\n",
    "def extract_entities_relationships(prompt_template):\n",
    "    start = timer()\n",
    "    files = glob.glob(f\"../hp_text/hp_test.txt\")\n",
    "    system_msg = \"You are an expert in knowledge graph construction and the Harry Potter series. Your task is to generate structured data suitable for a Neo4j graph database, representing key entities (characters, locations, magical_objects, spells, potions, creatures) and their relationships.\"\n",
    "    results = []\n",
    "    for i, file in enumerate(files):\n",
    "        print(f\"Extracting entities and relationships for {file}\")\n",
    "        try:\n",
    "            with open(file, \"r\") as f:\n",
    "                text = f.read().rstrip()\n",
    "                prompt = Template(prompt_template).substitute(ctext=text)\n",
    "                result = process_gpt(prompt, system_msg=system_msg)\n",
    "                print(result)\n",
    "                results.append(json.loads(result))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "    end = timer()\n",
    "    print(f\"Pipeline completed in {end-start} seconds\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# Function to take a json-object of entitites and relationships and generate cypher query for creating those entities\n",
    "def generate_cypher(json_obj):\n",
    "    e_statements = []\n",
    "    r_statements = []\n",
    "\n",
    "    e_label_map = {}\n",
    "\n",
    "    # loop through our json object\n",
    "    for i, obj in enumerate(json_obj):\n",
    "        print(f\"Generating cypher for file {i+1} of {len(json_obj)}\")\n",
    "        for entity in obj[\"entities\"]:\n",
    "            label = entity[\"label\"]\n",
    "            id = entity[\"id\"]\n",
    "            id = id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "            properties = {k: v for k, v in entity.items() if k not in [\"label\", \"id\"]}\n",
    "\n",
    "            cypher = f'MERGE (n:{label} {{id: \"{id}\"}})'\n",
    "            if properties:\n",
    "                props_str = \", \".join(\n",
    "                    [f'n.{key} = \"{val}\"' for key, val in properties.items()]\n",
    "                )\n",
    "                cypher += f\" ON CREATE SET {props_str}\"\n",
    "            e_statements.append(cypher)\n",
    "            e_label_map[id] = label\n",
    "\n",
    "        for rs in obj[\"relationships\"]:\n",
    "            src_id, rs_type, tgt_id = rs.split(\"|\")\n",
    "            src_id = src_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "            tgt_id = tgt_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "\n",
    "            src_label = e_label_map[src_id]\n",
    "            tgt_label = e_label_map[tgt_id]\n",
    "\n",
    "            cypher = f'MERGE (a:{src_label} {{id: \"{src_id}\"}}) MERGE (b:{tgt_label} {{id: \"{tgt_id}\"}}) MERGE (a)-[:{rs_type}]->(b)'\n",
    "            r_statements.append(cypher)\n",
    "\n",
    "    with open(\"cyphers.txt\", \"w\") as outfile:\n",
    "        outfile.write(\"\\n\".join(e_statements + r_statements))\n",
    "\n",
    "    return e_statements + r_statements\n",
    "\n",
    "\n",
    "# Final function to bring all the steps together\n",
    "def ingestion_pipeline(folders):\n",
    "    # Extrating the entites and relationships from each folder, append into one json_object\n",
    "    entities_relationships = []\n",
    "    for key, value in folders.items():\n",
    "        entities_relationships.extend(extract_entities_relationships(key, value))\n",
    "\n",
    "    # Generate and execute cypher statements\n",
    "    cypher_statements = generate_cypher(entities_relationships)\n",
    "    for i, stmt in enumerate(cypher_statements):\n",
    "        print(f\"Executing cypher statement {i+1} of {len(cypher_statements)}\")\n",
    "        try:\n",
    "            gds.execute_query(stmt)\n",
    "        except Exception as e:\n",
    "            with open(\"failed_statements.txt\", \"w\") as f:\n",
    "                f.write(f\"{stmt} - Exception: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Extract characters and relationships from the following text to construct a knowledge graph for Neo4j.\n",
    "    \n",
    "    Instructions:\n",
    "    \n",
    "    1. Identify Characters (nodes)\n",
    "    \n",
    "    2. Identify relationships (edges) between characters.\n",
    "    \n",
    "    3. The output should look like :\n",
    "    {\n",
    "        \"char_obj\": [{\"id\":string, \"name\":string}],\n",
    "        \"char_sub\": [{\"id\":string, \"name\":string}]\n",
    "        \"action\": [\"char_obj['id']|HAS_ACTION|char_sub['id']\"]\n",
    "    }\n",
    "    \n",
    "    Example Output:\n",
    "    {\n",
    "        \"char_obj\": [{\"id\":1, \"name\":Harry}],\n",
    "        \"char_sub\": [{\"id\":2, \"name\":Ron}]\n",
    "        \"action\": [\"1|make friend with|2\"]\n",
    "    }\n",
    "    \n",
    "    Example Output:\n",
    "    {\n",
    "        \"char_obj\": [{\"id\":7, \"name\":McGonagall}],\n",
    "        \"char_sub\": [{\"id\"5, \"name\":Hagrid}]\n",
    "        \"action\": [\"7|whispered, patting|5\"]\n",
    "    }\n",
    "    \n",
    "    \n",
    "    Text:\n",
    "    $ctext\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting entities and relationships for ../hp_text/hp_test.txt\n",
      "{\n",
      "    \"char_obj\": [\n",
      "        {\"id\": \"1\", \"name\": \"Mr. Dursley\"},\n",
      "        {\"id\": \"2\", \"name\": \"Mrs. Dursley\"},\n",
      "        {\"id\": \"3\", \"name\": \"Dudley\"}\n",
      "    ],\n",
      "    \"char_sub\": [\n",
      "        {\"id\": \"4\", \"name\": \"Grunnings\"}\n",
      "    ],\n",
      "    \"action\": [\n",
      "        \"1|is director of|4\",\n",
      "        \"2|spied on|neighbors\",\n",
      "        \"1|married to|2\",\n",
      "        \"1|parent of|3\",\n",
      "        \"2|parent of|3\"\n",
      "    ]\n",
      "}\n",
      "Pipeline completed in 65.1079055830487 seconds\n",
      "[{'char_obj': [{'id': '1', 'name': 'Mr. Dursley'}, {'id': '2', 'name': 'Mrs. Dursley'}, {'id': '3', 'name': 'Dudley'}], 'char_sub': [{'id': '4', 'name': 'Grunnings'}], 'action': ['1|is director of|4', '2|spied on|neighbors', '1|married to|2', '1|parent of|3', '2|parent of|3']}]\n"
     ]
    }
   ],
   "source": [
    "print(extract_entities_relationships(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
